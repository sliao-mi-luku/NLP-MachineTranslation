{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EncoderDecoder_English_French_translator_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VLYa2a4FOtx"
      },
      "source": [
        "# English-to-French translation by Encoder-Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oNmk3EBz6ld"
      },
      "source": [
        "In this notebook, I used the Encoder-Decoder architecture to translate the English sentences into French.\n",
        "\n",
        "---\n",
        "**The dataset**\n",
        "\n",
        "This notebook uses the dataset provided by [Udacity's NLP Nanodegree Course](https://www.udacity.com/course/natural-language-processing-nanodegree--nd892). The dataset is a subset extracted from the [WMT](http://www.statmt.org/) dataset. It contains 137,861 English sentences and their translations in French.\n",
        "\n",
        "To run this notebook, simply upload the training data onto the Google Colab workspace (assuming that you have those files). If you don't have the files I used, you can upload your own dataset (even in different languages), and rewrite your data preprocessing codes.\n",
        "\n",
        "---\n",
        "**Computing resource**\n",
        "\n",
        "This notebook was run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O18iLAeDxM7E"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLOu2cx5yLrR",
        "outputId": "13031d5c-c3c4-43d7-c490-60f786d6f166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Input, Dense, TimeDistributed, Activation\n",
        "from tensorflow.keras.layers import RepeatVector, Bidirectional, Attention, Concatenate, Dot\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code below is used to confirm that we're using GPU\n",
        "\"\"\"\n",
        "\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Found GPU at: /device:GPU:0\n",
            "\n",
            "\n",
            "Mon Nov  2 06:09:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    38W / 300W |    433MiB / 16130MiB |      3%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wArW2zRGxpVN"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "Load the dataset (it could be your own dataset) from the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4HztZsykpf"
      },
      "source": [
        "## Load English sentences\n",
        "with open('small_vocab_en', 'r') as f:\n",
        "    eng_raw_data = f.read()\n",
        "          \n",
        "english_sentences = eng_raw_data.split('\\n')\n",
        "\n",
        "## Load French sentences\n",
        "with open('small_vocab_fr', 'r') as f:\n",
        "    fr_raw_data = f.read()\n",
        "          \n",
        "french_sentences = fr_raw_data.split('\\n')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj9FDrFSy-k7",
        "outputId": "8b55cd9c-61d5-4335-c6a9-1c68035e4436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Display some info\n",
        "\n",
        "print(\"sentences in the English corpus: {}\".format(len(english_sentences)))\n",
        "print(\"sentences in the French corpus: {}\".format(len(french_sentences)))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"first 3 English/French sentences:\\n\")\n",
        "\n",
        "for i in range(3):\n",
        "    print(english_sentences[i])\n",
        "    print(french_sentences[i])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentences in the English corpus: 137861\n",
            "sentences in the French corpus: 137861\n",
            "\n",
            "\n",
            "first 3 English/French sentences:\n",
            "\n",
            "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "\n",
            "\n",
            "the united states is usually chilly during july , and it is usually freezing in november .\n",
            "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "\n",
            "\n",
            "california is usually quiet during march , and it is usually hot in june .\n",
            "california est généralement calme en mars , et il est généralement chaud en juin .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNobNhzEyPEy"
      },
      "source": [
        "We use `collections.Counter` to count the distinct words in both languages, and use the `most_common()` method to see the most frequently used words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRyVV5I5y_T5",
        "outputId": "f5df5d9b-e70c-4cc3-9d19-3e3850cedae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "## Size of the English vocabulary\n",
        "english_corpus = [w for sentence in english_sentences for w in sentence.split()]\n",
        "english_vocab_counter = Counter(english_corpus)\n",
        "english_vocab_size = len(english_vocab_counter)\n",
        "\n",
        "print(\"Size of the English corpus: {}\".format(len(english_corpus)))\n",
        "print(\"Vocab size of English: {}\".format(english_vocab_size))\n",
        "print(\"10 most frequent English vocab: {}\".format([x[0] for x in english_vocab_counter.most_common(10)]))\n",
        "print(\"longest length of sentence: {}\".format(max(len(sentence.split()) for sentence in english_sentences)))\n",
        "print(\"\\n\")\n",
        "\n",
        "## Size of the French vocabulary\n",
        "french_corpus = [w for sentence in french_sentences for w in sentence.split()]\n",
        "french_vocab_counter = Counter(french_corpus)\n",
        "french_vocab_size = len(french_vocab_counter)\n",
        "\n",
        "print(\"Size of the French corpus: {}\".format(len(french_corpus)))\n",
        "print(\"Vocab size of French: {}\".format(french_vocab_size))\n",
        "print(\"10 most frequent French vocab: {}\".format([x[0] for x in french_vocab_counter.most_common(10)]))\n",
        "print(\"longest length of sentence: {}\".format(max(len(sentence.split()) for sentence in french_sentences)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the English corpus: 1823250\n",
            "Vocab size of English: 227\n",
            "10 most frequent English vocab: ['is', ',', '.', 'in', 'it', 'during', 'the', 'but', 'and', 'sometimes']\n",
            "longest length of sentence: 17\n",
            "\n",
            "\n",
            "Size of the French corpus: 1961295\n",
            "Vocab size of French: 355\n",
            "10 most frequent French vocab: ['est', '.', ',', 'en', 'il', 'les', 'mais', 'et', 'la', 'parfois']\n",
            "longest length of sentence: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY0sGS8zh5zU"
      },
      "source": [
        "We see that the longest length of English sentences is 17, and the longest length of French sentences is 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG8n87NYzS97"
      },
      "source": [
        "# Create training, validation, and test datasets\n",
        "\n",
        "We use `sklearn.model_selection.train_test_split` split the dataset (137,861 sentences) into:\n",
        "\n",
        "- training dataset of 120,000 sentences,\n",
        "\n",
        "- validation dataset of 7,861 sentences, and\n",
        "\n",
        "- test dataset of 10,000 sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDggExBWpFAP",
        "outputId": "d72219f6-102a-4064-cc01-1eac8d3791c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Split into 120000 training, 7861 validation, and 10000 test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# separate test data\n",
        "X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(english_sentences, french_sentences, test_size = 10000, random_state = 1)\n",
        "\n",
        "# separate train and validation data\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_valid, Y_train_valid, test_size = 7861, random_state = 1)\n",
        "\n",
        "# check sizes\n",
        "print(\"number of training data: {} / {}\".format(len(X_train), len(Y_train)))\n",
        "print(\"number of valid data: {} / {}\".format(len(X_valid), len(Y_valid)))\n",
        "print(\"number of test data: {} / {}\".format(len(X_test), len(Y_test)))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training data: 120000 / 120000\n",
            "number of valid data: 7861 / 7861\n",
            "number of test data: 10000 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxeSECgUdweC"
      },
      "source": [
        "# Build TensorFlow input pipelines\n",
        "\n",
        "Use `tf.data.Dataset.from_tensor_slices` to convert the data into tensorflow dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPSZ0oGQd1oh",
        "outputId": "536a7505-4795-4429-e563-848adce1ba2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "\n",
        "next(iter(train_dataset))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'california is usually hot during july , and it is never wet in april .'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'californie est g\\xc3\\xa9n\\xc3\\xa9ralement chaud en juillet , et il est jamais humide en avril .'>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUsGicwR6hJD",
        "outputId": "0439b0f2-5b94-4120-a1d8-7fe47109fb8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
        "\n",
        "next(iter(valid_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'paris is dry during august , and it is usually beautiful in july .'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b\"paris est sec au mois d' ao\\xc3\\xbbt , et il est g\\xc3\\xa9n\\xc3\\xa9ralement beau en juillet .\">)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AfJ3vNP6m5i",
        "outputId": "0e2ca235-6510-4892-c507-a3c9096265dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "next(iter(test_dataset))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'california is sometimes warm during fall , and it is usually beautiful in april .'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b\"californie est parfois chaud pendant l' automne , et il est g\\xc3\\xa9n\\xc3\\xa9ralement beau en avril .\">)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoxNnAtiGqTR"
      },
      "source": [
        "# Tokenize the words\n",
        "\n",
        "We use the method `build_from_corpus` of `tfds.deprecated.text.SubwordTextEncoder` to tokenize the English and French sentences\n",
        "\n",
        "The [SubwordTextEncoder](https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder) can encode a word by its subwords if that word was not seen in its dictionaty.\n",
        "\n",
        "We specified the `vocab_size` so that the tokens wll give integers from [1, vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhy3L1TMzCgB"
      },
      "source": [
        "## Subword Tokenizer\n",
        "english_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus((eng.numpy() for eng, fr in train_dataset), target_vocab_size = 2**13)\n",
        "french_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus((fr.numpy() for eng, fr in train_dataset), target_vocab_size = 2**13)\n",
        "\n",
        "\n",
        "## Vocabulary size (+2 for start and end)\n",
        "input_vocab_size = english_tokenizer.vocab_size + 2\n",
        "output_vocab_size = french_tokenizer.vocab_size + 2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6iG_HrZG9hL"
      },
      "source": [
        "The test below will tokenize an English sentence into tokens by the `encode` method of the tokenizer. The token will then be decoded back by using the `decode` method. After decoding we should get the original sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XooacSNgF_uo",
        "outputId": "9a414cfa-7cfc-4527-aeb4-9f1e7bd56626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Test the tokenization\n",
        "\n",
        "sample_sentence = X_valid[100]\n",
        "\n",
        "encoded_sample_sentence = english_tokenizer.encode(sample_sentence)\n",
        "\n",
        "print(\"input sentence: {}\".format(sample_sentence))\n",
        "print(\"tokens: {}\".format(encoded_sample_sentence))\n",
        "print(\"tokenized sentence: {}\".format(english_tokenizer.decode(encoded_sample_sentence)))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"detail of tokenizing:\")\n",
        "for k in encoded_sample_sentence:\n",
        "    print(\"{} ---> {}\".format(k, english_tokenizer.decode([k])))\n",
        "\n",
        "print(\"\\n\")\n",
        "## More sanity check on the first 5 sentences in the training dataset\n",
        "for i in range(5):\n",
        "    print(X_train[i] == english_tokenizer.decode(english_tokenizer.encode(X_train[i])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input sentence: the pear is your most loved fruit , but the grapefruit is her most loved .\n",
            "tokens: [7, 107, 1, 31, 15, 27, 16, 2, 8, 7, 92, 1, 34, 15, 89, 3]\n",
            "tokenized sentence: the pear is your most loved fruit , but the grapefruit is her most loved .\n",
            "\n",
            "\n",
            "detail of tokenizing:\n",
            "7 ---> the \n",
            "107 ---> pear \n",
            "1 ---> is \n",
            "31 ---> your \n",
            "15 ---> most \n",
            "27 ---> loved \n",
            "16 ---> fruit\n",
            "2 --->  , \n",
            "8 ---> but \n",
            "7 ---> the \n",
            "92 ---> grapefruit \n",
            "1 ---> is \n",
            "34 ---> her \n",
            "15 ---> most \n",
            "89 ---> loved\n",
            "3 --->  .\n",
            "\n",
            "\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtH_dC0rHh7V"
      },
      "source": [
        "# The tokenize+pad function\n",
        "\n",
        "The tokenize function takes a list of sentences and its language tokenizer as inputs. It tokenizes the sentences, and add a **start token** and an **end token** in each sentence\n",
        "\n",
        "There are in total N tokens in the tokenizer, with labels from 1 to N-1.\n",
        "\n",
        "We use **N as the start token**, and **N+1 as the end token**.\n",
        "\n",
        "To get N, we use the `vocab_size` attribute of the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7XpTpYtWmE"
      },
      "source": [
        "MAX_LENGTH = 25             # maximum length of the input sentence\n",
        "BUFFER_SIZE = 20000         # the size of the shuffle buffer\n",
        "BATCH_SIZE = 64             # the batch size\n",
        "\n",
        "\n",
        "def tokenize(eng_sentence, fr_sentence):\n",
        "\n",
        "    eng_sentence = [english_tokenizer.vocab_size] + english_tokenizer.encode(eng_sentence.numpy()) + [english_tokenizer.vocab_size+1]\n",
        "    fr_sentence =  [french_tokenizer.vocab_size] + french_tokenizer.encode(fr_sentence.numpy()) + [french_tokenizer.vocab_size+1]\n",
        "\n",
        "    return eng_sentence, fr_sentence\n",
        "\n",
        "\n",
        "def tf_tokenize(eng_sentence, fr_sentence):\n",
        "\n",
        "    res_eng, res_fr = tf.py_function(tokenize, [eng_sentence, fr_sentence], [tf.int64, tf.int64])\n",
        "\n",
        "    res_eng.set_shape([None])\n",
        "    res_fr.set_shape([None])\n",
        "\n",
        "    return res_eng, res_fr\n",
        "\n",
        "\n",
        "def filter_max_length(x, y, max_length = MAX_LENGTH):\n",
        "\n",
        "    return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMwbCsT83T37"
      },
      "source": [
        "## Propress the training data\n",
        "\n",
        "The code below tokenizes, add SOS & EOS, filter out sentences that are too long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OtHHw2KgaXK",
        "outputId": "7e35be3a-8679-4dec-cb0b-97ef2a672139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tokenize the training dataset\n",
        "train_dataset = train_dataset.map(tf_tokenize)\n",
        "# remove sentences that are too long\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the data to memory\n",
        "train_dataset = train_dataset.cache()\n",
        "# shuffle\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "# padding\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE, padded_shapes = ([MAX_LENGTH], [MAX_LENGTH]))\n",
        "# prefetching\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# see a batch\n",
        "eng_batch, fr_batch = next(iter(train_dataset))\n",
        "eng_batch, fr_batch"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 25), dtype=int64, numpy=\n",
              " array([[528,  34,  15, ...,   0,   0,   0],\n",
              "        [528,  20,   1, ...,   0,   0,   0],\n",
              "        [528,  18,  25, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [528,  56,  13, ...,   0,   0,   0],\n",
              "        [528,  30,  73, ...,   0,   0,   0],\n",
              "        [528,  23,   1, ...,   0,   0,   0]])>,\n",
              " <tf.Tensor: shape=(64, 25), dtype=int64, numpy=\n",
              " array([[717,  22, 121, ...,   0,   0,   0],\n",
              "        [717,  34,   1, ...,   0,   0,   0],\n",
              "        [717,  36,  37, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [717, 154, 122, ...,   0,   0,   0],\n",
              "        [717,   5, 571, ...,   0,   0,   0],\n",
              "        [717,  94,   1, ...,   0,   0,   0]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGEuKPh0TTe9"
      },
      "source": [
        "## Preprocess the validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v80aQfZbTW4w",
        "outputId": "826e2c9f-dd49-4541-9418-722caad0828a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tokenize the valid dataset\n",
        "valid_dataset = valid_dataset.map(tf_tokenize)\n",
        "# remove sentences that are too long\n",
        "valid_dataset = valid_dataset.filter(filter_max_length)\n",
        "# cache the data to memory\n",
        "valid_dataset = valid_dataset.cache()\n",
        "# shuffle\n",
        "valid_dataset = valid_dataset.shuffle(BUFFER_SIZE)\n",
        "# padding\n",
        "valid_dataset = valid_dataset.padded_batch(BATCH_SIZE, padded_shapes = ([MAX_LENGTH], [MAX_LENGTH]))\n",
        "# prefetching\n",
        "valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# see a batch\n",
        "eng_batch, fr_batch = next(iter(valid_dataset))\n",
        "eng_batch, fr_batch"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 25), dtype=int64, numpy=\n",
              " array([[528,  21,   1, ...,   0,   0,   0],\n",
              "        [528,  23,   1, ...,   0,   0,   0],\n",
              "        [528,  94,  86, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [528,  18,  25, ...,   0,   0,   0],\n",
              "        [528,  20,   1, ...,   0,   0,   0],\n",
              "        [528,  26,   1, ...,   0,   0,   0]])>,\n",
              " <tf.Tensor: shape=(64, 25), dtype=int64, numpy=\n",
              " array([[717,  31,   1, ...,   0,   0,   0],\n",
              "        [717,  64,   1, ...,   0,   0,   0],\n",
              "        [717,  99, 152, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [717,  36,  37, ...,   0,   0,   0],\n",
              "        [717,  34,   1, ...,   0,   0,   0],\n",
              "        [717,   9,  38, ...,   0,   0,   0]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYIaZo28ZFm4"
      },
      "source": [
        "## Preprocess the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfjaLce7ZHf6",
        "outputId": "becbde14-622f-4306-95da-0f2e3a773a9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tokenize the test dataset\n",
        "test_dataset = test_dataset.map(tf_tokenize)\n",
        "# remove sentences that are too long\n",
        "test_dataset = test_dataset.filter(filter_max_length)\n",
        "# cache the data to memory\n",
        "test_dataset = test_dataset.cache()\n",
        "# shuffle\n",
        "test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
        "# padding\n",
        "test_dataset = test_dataset.padded_batch(1, padded_shapes = ([MAX_LENGTH], [MAX_LENGTH]))\n",
        "# prefetching\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# see a batch\n",
        "eng_batch, fr_batch = next(iter(test_dataset))\n",
        "eng_batch, fr_batch"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 25), dtype=int64, numpy=\n",
              " array([[528,  30, 147,  91, 130, 131, 116,   3, 529,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>,\n",
              " <tf.Tensor: shape=(1, 25), dtype=int64, numpy=\n",
              " array([[717,   5, 143, 171, 148, 169,  91, 164,   2, 718,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I09zUHew54Hp"
      },
      "source": [
        "## Encoder-Decoder Architecture\n",
        "\n",
        "The NN architecture contains:\n",
        "\n",
        "1. Embedding\n",
        "2. Bidirectional GRU\n",
        "3. RepeatVector layer\n",
        "4. Birirectional GRU\n",
        "5. TimeDistributed layer\n",
        "6. Softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKslJe7j42Uk"
      },
      "source": [
        "class EncoderDecoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, rnn_class, output_dim, embedding_dim, encoder_units, decoder_units, input_vocab_size, output_vocab_size):\n",
        "\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "\n",
        "        self.Embedding = Embedding(input_vocab_size, embedding_dim)\n",
        "\n",
        "        if rnn_class.upper() == \"GRU\":\n",
        "            self.Bidirectional_encoder = Bidirectional(GRU(encoder_units))\n",
        "            self.Bidirectional_decoder = Bidirectional(GRU(decoder_units, return_sequences = True))\n",
        "        elif rnn_class.upper() == \"LSTM\":\n",
        "            self.Bidirectional_encoder = Bidirectional(LSTM(encoder_units))\n",
        "            self.Bidirectional_decoder = Bidirectional(LSTM(decoder_units, return_sequences = True))\n",
        "        \n",
        "        self.RepeatVector = RepeatVector(output_dim)\n",
        "\n",
        "        self.TimeDistributed = TimeDistributed(Dense(output_vocab_size))\n",
        "\n",
        "        self.Activation = Activation('softmax')\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        x = self.Embedding(x)\n",
        "        x = self.Bidirectional_encoder(x)\n",
        "        x = self.RepeatVector(x)\n",
        "        x = self.Bidirectional_decoder(x)\n",
        "        x = self.TimeDistributed(x)\n",
        "        y = self.Activation(x)\n",
        "\n",
        "        return y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3g_iCVFnfzc"
      },
      "source": [
        "## Optimizer and Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns5R41b0nlKz"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
        "\n",
        "loss_criterion = tf.keras.losses.SparseCategoricalCrossentropy(name = 'sparse_categorical_crossentropy')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw69nL74yKFc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMGoQLgHylnC"
      },
      "source": [
        "train_step_signature = [tf.TensorSpec(shape=(None, None), dtype = tf.int64), tf.TensorSpec(shape=(None, None), dtype = tf.int64)]\n",
        "\n",
        "@tf.function(input_signature = train_step_signature)\n",
        "def train_step(input, target):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        preds = translator(input)\n",
        "\n",
        "        loss = loss_criterion(target, preds)\n",
        "\n",
        "    gradients = tape.gradient(loss, translator.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, translator.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_acc(target, preds)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl5hYESKOxAd"
      },
      "source": [
        "valid_step_signature = [tf.TensorSpec(shape=(None, None), dtype = tf.int64), tf.TensorSpec(shape=(None, None), dtype = tf.int64)]\n",
        "\n",
        "@tf.function(input_signature = valid_step_signature)\n",
        "def valid_step(input, target):\n",
        "\n",
        "    preds = translator(input)\n",
        "    \n",
        "    loss = loss_criterion(target, preds)\n",
        "\n",
        "    valid_loss(loss)\n",
        "    valid_acc(target, preds)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_CGYAuRadC"
      },
      "source": [
        "test_step_signature = [tf.TensorSpec(shape=(None, None), dtype = tf.int64), tf.TensorSpec(shape=(None, None), dtype = tf.int64)]\n",
        "\n",
        "@tf.function(input_signature = test_step_signature)\n",
        "def test_step(input, target):\n",
        "\n",
        "    preds = translator(input)\n",
        "    \n",
        "    loss = loss_criterion(target, preds)\n",
        "\n",
        "    test_loss(loss)\n",
        "    test_acc(target, preds)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uBpS6CNy6y6",
        "outputId": "e13c216c-0f5a-41c4-8589-65ec73c57c0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "train_loss_history = []\n",
        "valid_loss_history = []\n",
        "\n",
        "\n",
        "## Create the translator\n",
        "translator = EncoderDecoder(rnn_class = 'LSTM', output_dim = MAX_LENGTH, embedding_dim = 256, encoder_units = 128, decoder_units = 128, input_vocab_size = input_vocab_size, output_vocab_size = output_vocab_size)\n",
        "\n",
        "## Initialize metrics\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_acc')\n",
        "\n",
        "valid_loss = tf.keras.metrics.Mean(name = 'valid_loss')\n",
        "valid_acc = tf.keras.metrics.SparseCategoricalAccuracy(name = 'valid_acc')\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_acc.reset_states()\n",
        "\n",
        "    valid_loss.reset_states()\n",
        "    valid_acc.reset_states()\n",
        "\n",
        "    \n",
        "    for (batch, (input, target)) in enumerate(train_dataset):\n",
        "\n",
        "        train_step(input, target)\n",
        "        \n",
        "        if batch % 500 == 0:\n",
        "            print(\"Epoch {}\\t Batch {}\\t Loss {:.4f}\\t Acc {:.4f}\".format(epoch, batch, train_loss.result(), train_acc.result()))\n",
        "    \n",
        "\n",
        "    for valid_x, valid_y in valid_dataset:\n",
        "\n",
        "        valid_step(valid_x, valid_y)\n",
        "\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Epoch {}\\t Train_Loss {:.4f}\\t Train_Acc {:.4f}\\t  Val_Loss {:.4f}\\t Val_Acc {:.4}\\t Time: {:.1f} s\".format(epoch, train_loss.result(), train_acc.result(),\n",
        "                                                                                   valid_loss.result(), valid_acc.result(), time.time() - start))\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    train_loss_history.append(train_loss.result())\n",
        "    valid_loss_history.append(valid_loss.result())\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\t Batch 0\t Loss 6.5793\t Acc 0.0006\n",
            "Epoch 1\t Batch 500\t Loss 2.3427\t Acc 0.4834\n",
            "Epoch 1\t Batch 1000\t Loss 1.9142\t Acc 0.5444\n",
            "Epoch 1\t Batch 1500\t Loss 1.6833\t Acc 0.5834\n",
            "\n",
            "\n",
            "Epoch 1\t Train_Loss 1.5559\t Train_Acc 0.6081\t  Val_Loss 0.9837\t Val_Acc 0.7254\t Time: 76.3 s\n",
            "\n",
            "\n",
            "Epoch 2\t Batch 0\t Loss 0.9295\t Acc 0.7525\n",
            "Epoch 2\t Batch 500\t Loss 0.9191\t Acc 0.7406\n",
            "Epoch 2\t Batch 1000\t Loss 0.8623\t Acc 0.7551\n",
            "Epoch 2\t Batch 1500\t Loss 0.8138\t Acc 0.7676\n",
            "\n",
            "\n",
            "Epoch 2\t Train_Loss 0.7773\t Train_Acc 0.7770\t  Val_Loss 0.6219\t Val_Acc 0.819\t Time: 28.3 s\n",
            "\n",
            "\n",
            "Epoch 3\t Batch 0\t Loss 0.5432\t Acc 0.8438\n",
            "Epoch 3\t Batch 500\t Loss 0.5555\t Acc 0.8364\n",
            "Epoch 3\t Batch 1000\t Loss 0.5136\t Acc 0.8491\n",
            "Epoch 3\t Batch 1500\t Loss 0.4759\t Acc 0.8613\n",
            "\n",
            "\n",
            "Epoch 3\t Train_Loss 0.4505\t Train_Acc 0.8695\t  Val_Loss 0.3460\t Val_Acc 0.9032\t Time: 28.4 s\n",
            "\n",
            "\n",
            "Epoch 4\t Batch 0\t Loss 0.3661\t Acc 0.8775\n",
            "Epoch 4\t Batch 500\t Loss 0.2993\t Acc 0.9167\n",
            "Epoch 4\t Batch 1000\t Loss 0.2784\t Acc 0.9221\n",
            "Epoch 4\t Batch 1500\t Loss 0.2612\t Acc 0.9264\n",
            "\n",
            "\n",
            "Epoch 4\t Train_Loss 0.2508\t Train_Acc 0.9290\t  Val_Loss 0.2136\t Val_Acc 0.9385\t Time: 28.6 s\n",
            "\n",
            "\n",
            "Epoch 5\t Batch 0\t Loss 0.2417\t Acc 0.9319\n",
            "Epoch 5\t Batch 500\t Loss 0.1956\t Acc 0.9430\n",
            "Epoch 5\t Batch 1000\t Loss 0.1867\t Acc 0.9455\n",
            "Epoch 5\t Batch 1500\t Loss 0.1799\t Acc 0.9472\n",
            "\n",
            "\n",
            "Epoch 5\t Train_Loss 0.1749\t Train_Acc 0.9487\t  Val_Loss 0.1731\t Val_Acc 0.9499\t Time: 28.5 s\n",
            "\n",
            "\n",
            "Epoch 6\t Batch 0\t Loss 0.1939\t Acc 0.9281\n",
            "Epoch 6\t Batch 500\t Loss 0.1493\t Acc 0.9559\n",
            "Epoch 6\t Batch 1000\t Loss 0.1446\t Acc 0.9572\n",
            "Epoch 6\t Batch 1500\t Loss 0.1402\t Acc 0.9585\n",
            "\n",
            "\n",
            "Epoch 6\t Train_Loss 0.1376\t Train_Acc 0.9592\t  Val_Loss 0.1437\t Val_Acc 0.9569\t Time: 28.6 s\n",
            "\n",
            "\n",
            "Epoch 7\t Batch 0\t Loss 0.1542\t Acc 0.9500\n",
            "Epoch 7\t Batch 500\t Loss 0.1188\t Acc 0.9641\n",
            "Epoch 7\t Batch 1000\t Loss 0.1171\t Acc 0.9647\n",
            "Epoch 7\t Batch 1500\t Loss 0.1149\t Acc 0.9653\n",
            "\n",
            "\n",
            "Epoch 7\t Train_Loss 0.1129\t Train_Acc 0.9658\t  Val_Loss 0.1174\t Val_Acc 0.9663\t Time: 29.2 s\n",
            "\n",
            "\n",
            "Epoch 8\t Batch 0\t Loss 0.2264\t Acc 0.9381\n",
            "Epoch 8\t Batch 500\t Loss 0.1034\t Acc 0.9688\n",
            "Epoch 8\t Batch 1000\t Loss 0.1016\t Acc 0.9694\n",
            "Epoch 8\t Batch 1500\t Loss 0.0984\t Acc 0.9703\n",
            "\n",
            "\n",
            "Epoch 8\t Train_Loss 0.0967\t Train_Acc 0.9707\t  Val_Loss 0.1096\t Val_Acc 0.9679\t Time: 28.8 s\n",
            "\n",
            "\n",
            "Epoch 9\t Batch 0\t Loss 0.1421\t Acc 0.9513\n",
            "Epoch 9\t Batch 500\t Loss 0.0891\t Acc 0.9731\n",
            "Epoch 9\t Batch 1000\t Loss 0.0885\t Acc 0.9732\n",
            "Epoch 9\t Batch 1500\t Loss 0.0855\t Acc 0.9740\n",
            "\n",
            "\n",
            "Epoch 9\t Train_Loss 0.0848\t Train_Acc 0.9742\t  Val_Loss 0.1046\t Val_Acc 0.9698\t Time: 28.7 s\n",
            "\n",
            "\n",
            "Epoch 10\t Batch 0\t Loss 0.1260\t Acc 0.9588\n",
            "Epoch 10\t Batch 500\t Loss 0.0758\t Acc 0.9770\n",
            "Epoch 10\t Batch 1000\t Loss 0.0757\t Acc 0.9770\n",
            "Epoch 10\t Batch 1500\t Loss 0.0742\t Acc 0.9774\n",
            "\n",
            "\n",
            "Epoch 10\t Train_Loss 0.0733\t Train_Acc 0.9777\t  Val_Loss 0.0910\t Val_Acc 0.9738\t Time: 28.6 s\n",
            "\n",
            "\n",
            "Epoch 11\t Batch 0\t Loss 0.1019\t Acc 0.9719\n",
            "Epoch 11\t Batch 500\t Loss 0.0680\t Acc 0.9792\n",
            "Epoch 11\t Batch 1000\t Loss 0.0682\t Acc 0.9792\n",
            "Epoch 11\t Batch 1500\t Loss 0.0667\t Acc 0.9797\n",
            "\n",
            "\n",
            "Epoch 11\t Train_Loss 0.0660\t Train_Acc 0.9799\t  Val_Loss 0.0898\t Val_Acc 0.9746\t Time: 28.6 s\n",
            "\n",
            "\n",
            "Epoch 12\t Batch 0\t Loss 0.0440\t Acc 0.9875\n",
            "Epoch 12\t Batch 500\t Loss 0.0618\t Acc 0.9814\n",
            "Epoch 12\t Batch 1000\t Loss 0.0610\t Acc 0.9814\n",
            "Epoch 12\t Batch 1500\t Loss 0.0600\t Acc 0.9817\n",
            "\n",
            "\n",
            "Epoch 12\t Train_Loss 0.0592\t Train_Acc 0.9820\t  Val_Loss 0.0837\t Val_Acc 0.9771\t Time: 28.7 s\n",
            "\n",
            "\n",
            "Epoch 13\t Batch 0\t Loss 0.1010\t Acc 0.9756\n",
            "Epoch 13\t Batch 500\t Loss 0.0553\t Acc 0.9832\n",
            "Epoch 13\t Batch 1000\t Loss 0.0551\t Acc 0.9832\n",
            "Epoch 13\t Batch 1500\t Loss 0.0540\t Acc 0.9836\n",
            "\n",
            "\n",
            "Epoch 13\t Train_Loss 0.0534\t Train_Acc 0.9837\t  Val_Loss 0.0804\t Val_Acc 0.979\t Time: 28.7 s\n",
            "\n",
            "\n",
            "Epoch 14\t Batch 0\t Loss 0.0374\t Acc 0.9887\n",
            "Epoch 14\t Batch 500\t Loss 0.0511\t Acc 0.9843\n",
            "Epoch 14\t Batch 1000\t Loss 0.0508\t Acc 0.9843\n",
            "Epoch 14\t Batch 1500\t Loss 0.0499\t Acc 0.9847\n",
            "\n",
            "\n",
            "Epoch 14\t Train_Loss 0.0489\t Train_Acc 0.9851\t  Val_Loss 0.0855\t Val_Acc 0.9776\t Time: 28.7 s\n",
            "\n",
            "\n",
            "Epoch 15\t Batch 0\t Loss 0.0497\t Acc 0.9831\n",
            "Epoch 15\t Batch 500\t Loss 0.0451\t Acc 0.9864\n",
            "Epoch 15\t Batch 1000\t Loss 0.0458\t Acc 0.9860\n",
            "Epoch 15\t Batch 1500\t Loss 0.0451\t Acc 0.9862\n",
            "\n",
            "\n",
            "Epoch 15\t Train_Loss 0.0446\t Train_Acc 0.9865\t  Val_Loss 0.0805\t Val_Acc 0.9798\t Time: 28.6 s\n",
            "\n",
            "\n",
            "Epoch 16\t Batch 0\t Loss 0.0879\t Acc 0.9781\n",
            "Epoch 16\t Batch 500\t Loss 0.0424\t Acc 0.9876\n",
            "Epoch 16\t Batch 1000\t Loss 0.0429\t Acc 0.9874\n",
            "Epoch 16\t Batch 1500\t Loss 0.0413\t Acc 0.9878\n",
            "\n",
            "\n",
            "Epoch 16\t Train_Loss 0.0410\t Train_Acc 0.9878\t  Val_Loss 0.0739\t Val_Acc 0.981\t Time: 28.8 s\n",
            "\n",
            "\n",
            "Epoch 17\t Batch 0\t Loss 0.0274\t Acc 0.9919\n",
            "Epoch 17\t Batch 500\t Loss 0.0373\t Acc 0.9886\n",
            "Epoch 17\t Batch 1000\t Loss 0.0379\t Acc 0.9884\n",
            "Epoch 17\t Batch 1500\t Loss 0.0378\t Acc 0.9886\n",
            "\n",
            "\n",
            "Epoch 17\t Train_Loss 0.0372\t Train_Acc 0.9887\t  Val_Loss 0.0739\t Val_Acc 0.981\t Time: 28.7 s\n",
            "\n",
            "\n",
            "Epoch 18\t Batch 0\t Loss 0.0187\t Acc 0.9950\n",
            "Epoch 18\t Batch 500\t Loss 0.0364\t Acc 0.9891\n",
            "Epoch 18\t Batch 1000\t Loss 0.0361\t Acc 0.9893\n",
            "Epoch 18\t Batch 1500\t Loss 0.0357\t Acc 0.9894\n",
            "\n",
            "\n",
            "Epoch 18\t Train_Loss 0.0352\t Train_Acc 0.9895\t  Val_Loss 0.0810\t Val_Acc 0.9801\t Time: 29.7 s\n",
            "\n",
            "\n",
            "Epoch 19\t Batch 0\t Loss 0.0439\t Acc 0.9862\n",
            "Epoch 19\t Batch 500\t Loss 0.0337\t Acc 0.9899\n",
            "Epoch 19\t Batch 1000\t Loss 0.0327\t Acc 0.9902\n",
            "Epoch 19\t Batch 1500\t Loss 0.0319\t Acc 0.9905\n",
            "\n",
            "\n",
            "Epoch 19\t Train_Loss 0.0316\t Train_Acc 0.9906\t  Val_Loss 0.0795\t Val_Acc 0.9806\t Time: 29.1 s\n",
            "\n",
            "\n",
            "Epoch 20\t Batch 0\t Loss 0.0255\t Acc 0.9937\n",
            "Epoch 20\t Batch 500\t Loss 0.0317\t Acc 0.9907\n",
            "Epoch 20\t Batch 1000\t Loss 0.0313\t Acc 0.9908\n",
            "Epoch 20\t Batch 1500\t Loss 0.0306\t Acc 0.9911\n",
            "\n",
            "\n",
            "Epoch 20\t Train_Loss 0.0300\t Train_Acc 0.9912\t  Val_Loss 0.0824\t Val_Acc 0.9803\t Time: 29.0 s\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CLJYlQcW2Cw",
        "outputId": "7869d31f-ebc6-4d7d-ec82-ae484d005fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "## Plot training and validation loss\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "plt.plot(range(1, EPOCHS+1), train_loss_history, 'b', label = \"Train\")\n",
        "plt.plot(range(1, EPOCHS+1), valid_loss_history, 'r', label = \"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.xticks(range(0, 21, 2))\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ROSNAfLnEXX"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckzpHYbeXiqb"
      },
      "source": [
        "## Bleu score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGikTx8iYJlD"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szW_iu5BYNUI",
        "outputId": "87b46b23-92d6-4f79-9728-a793c8c51926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "# The test dataset has 10,000 sentence pairs\n",
        "\n",
        "test_bleu_score = 0\n",
        "\n",
        "smoothing_func = SmoothingFunction()\n",
        "\n",
        "# loss, acc and \n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_acc')\n",
        "\n",
        "test_loss.reset_states()\n",
        "test_acc.reset_states()\n",
        "\n",
        "for (test_n, (test_x, test_y)) in enumerate(test_dataset):\n",
        "\n",
        "    # Accuracy\n",
        "    test_step(input, target)\n",
        "\n",
        "    # prediction (logits)\n",
        "    pred = translator(test_x)\n",
        "\n",
        "    # Squeeze for further processing\n",
        "    pred = tf.squeeze(pred).numpy()\n",
        "\n",
        "    # prediction (tokens)\n",
        "    pred_tokens = tf.math.argmax(pred, axis = 1)\n",
        "\n",
        "    # convert to a list of words\n",
        "    translation = french_tokenizer.decode([w for w in pred_tokens if w < french_tokenizer.vocab_size and w != 0]).split()\n",
        "\n",
        "    # true translation\n",
        "    references = french_tokenizer.decode([w for w in tf.squeeze(test_y).numpy() if w < french_tokenizer.vocab_size and w != 0]).split()\n",
        "\n",
        "    # BLEU\n",
        "    test_bleu_score += sentence_bleu(references = [references], hypothesis = translation, smoothing_function = smoothing_func.method1)\n",
        "\n",
        "\n",
        "    if (test_n + 1) % 1000 == 0:\n",
        "        print(\"Test data loaded ({}/10000)\".format(test_n+1))\n",
        "\n",
        "\n",
        "print(\"Test data n = {}\".format(test_n))\n",
        "print(\"Test loss = {:4f}\".format(test_loss.result()))\n",
        "print(\"Test acc = {:4f}\".format(test_acc.result()))\n",
        "print(\"Test BLEU score = {:4f}\".format(test_bleu_score/(test_n+1)))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data loaded (1000/10000)\n",
            "Test data loaded (2000/10000)\n",
            "Test data loaded (3000/10000)\n",
            "Test data loaded (4000/10000)\n",
            "Test data loaded (5000/10000)\n",
            "Test data loaded (6000/10000)\n",
            "Test data loaded (7000/10000)\n",
            "Test data loaded (8000/10000)\n",
            "Test data loaded (9000/10000)\n",
            "Test data n = 9995\n",
            "Test loss = 0.005943\n",
            "Test acc = 0.999048\n",
            "Test BLEU score = 0.962317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ZqRRWpcK0G"
      },
      "source": [
        "# Translation Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTT7M9UnsyM",
        "outputId": "9b0f03e8-1f59-41e2-a026-f9b615670877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Sample from the test set randomly and translate\n",
        "\n",
        "import random\n",
        "\n",
        "random_index = random.randint(0, len(X_test))\n",
        "\n",
        "x = [X_test[random_index]]\n",
        "y = [Y_test[random_index]]\n",
        "\n",
        "sample_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "\n",
        "\n",
        "# tokenize the test dataset\n",
        "sample_dataset = sample_dataset.map(tf_tokenize)\n",
        "# remove sentences that are too long\n",
        "sample_dataset = sample_dataset.filter(filter_max_length)\n",
        "# cache the data to memory\n",
        "sample_dataset = sample_dataset.cache()\n",
        "# shuffle\n",
        "sample_dataset = sample_dataset.shuffle(BUFFER_SIZE)\n",
        "# padding\n",
        "sample_dataset = sample_dataset.padded_batch(1, padded_shapes = ([MAX_LENGTH], [MAX_LENGTH]))\n",
        "# prefetching\n",
        "sample_dataset = sample_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "for sample_x, sample_y in sample_dataset:\n",
        "\n",
        "    # Decode sample_x into an English sentence\n",
        "    sample_eng = english_tokenizer.decode([w for w in tf.squeeze(sample_x).numpy() if w < english_tokenizer.vocab_size])\n",
        "\n",
        "    # Decode sample_y into a french sentence\n",
        "    sample_fr = french_tokenizer.decode([w for w in tf.squeeze(sample_y).numpy() if w < french_tokenizer.vocab_size])\n",
        "\n",
        "    # Use translator to translate sample_x\n",
        "    pred = tf.squeeze(translator(sample_x, training = False)).numpy()\n",
        "    pred_tokens = tf.math.argmax(pred, axis = 1)\n",
        "    translation = french_tokenizer.decode([w for w in pred_tokens if w < french_tokenizer.vocab_size])\n",
        "\n",
        "    print(\"[eng]\\n{}\".format(sample_eng))\n",
        "    print(\"[fr]\\n{}\".format(sample_fr))\n",
        "    print(\"[translation]\\n{}\".format(translation))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[eng]\n",
            "the orange is their least favorite fruit , but the mango is your least favorite .\n",
            "[fr]\n",
            "l'orange est leur fruit préféré moins , mais la mangue est votre préféré moins .\n",
            "[translation]\n",
            "l'orange est leur fruit préféré moins , mais la mangue est votre préféré moins .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}