{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_English_French_translator_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VLYa2a4FOtx"
      },
      "source": [
        "# English-to-French translation by Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oNmk3EBz6ld"
      },
      "source": [
        "In this notebook, I used the [transformer network](https://arxiv.org/abs/1706.03762) to translate the English sentences into French.\n",
        "\n",
        "\n",
        "---\n",
        "**The original paper**\n",
        "\n",
        "A. Vaswani et al. (2017) **Attention Is All You Need**: https://arxiv.org/abs/1706.03762\n",
        "\n",
        "---\n",
        "**References**\n",
        "\n",
        "This notebook is guided by following the Transformer tutorial notebook:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/transformer\n",
        "\n",
        "\n",
        "---\n",
        "**The dataset**\n",
        "\n",
        "This notebook uses the dataset provided by [Udacity's NLP Nanodegree Course](https://www.udacity.com/course/natural-language-processing-nanodegree--nd892). The dataset is a subset extracted from the [WMT](http://www.statmt.org/) dataset. It contains 137,861 English sentences and their translations in French.\n",
        "\n",
        "To run this notebook, simply upload the training data onto the Google Colab workspace (assuming that you have those files). If you don't have the files I used, you can upload your own dataset (even in different languages), and rewrite your data preprocessing codes.\n",
        "\n",
        "---\n",
        "**Computing resource**\n",
        "\n",
        "This notebook was run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O18iLAeDxM7E"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLOu2cx5yLrR",
        "outputId": "d03c47dc-0953-41f6-e05c-327a85a4d641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Input, Dense, TimeDistributed, Activation\n",
        "from tensorflow.keras.layers import RepeatVector, Bidirectional, Attention, Concatenate, Dot\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code below is used to confirm that we're using GPU\n",
        "\"\"\"\n",
        "\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Found GPU at: /device:GPU:0\n",
            "\n",
            "\n",
            "Sun Oct  4 21:32:04 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    39W / 300W |    433MiB / 16130MiB |      7%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wArW2zRGxpVN"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "Load the dataset (it could be your own dataset) from the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4HztZsykpf"
      },
      "source": [
        "## Load English sentences\n",
        "with open('small_vocab_en', 'r') as f:\n",
        "    eng_raw_data = f.read()\n",
        "          \n",
        "english_sentences = eng_raw_data.split('\\n')\n",
        "\n",
        "## Load French sentences\n",
        "with open('small_vocab_fr', 'r') as f:\n",
        "    fr_raw_data = f.read()\n",
        "          \n",
        "french_sentences = fr_raw_data.split('\\n')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj9FDrFSy-k7",
        "outputId": "d3739c79-2d0f-4c0f-fdf1-0f3c6f97b4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "## Display some info\n",
        "\n",
        "print(\"sentences in the English corpus: {}\".format(len(english_sentences)))\n",
        "print(\"sentences in the French corpus: {}\".format(len(french_sentences)))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"first 3 English/French sentences:\\n\")\n",
        "\n",
        "for i in range(3):\n",
        "    print(english_sentences[i])\n",
        "    print(french_sentences[i])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentences in the English corpus: 137861\n",
            "sentences in the French corpus: 137861\n",
            "\n",
            "\n",
            "first 3 English/French sentences:\n",
            "\n",
            "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "\n",
            "\n",
            "the united states is usually chilly during july , and it is usually freezing in november .\n",
            "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "\n",
            "\n",
            "california is usually quiet during march , and it is usually hot in june .\n",
            "california est généralement calme en mars , et il est généralement chaud en juin .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNobNhzEyPEy"
      },
      "source": [
        "We use `collections.Counter` to count the distinct words in both languages, and use the `most_common()` method to see the most frequently used words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRyVV5I5y_T5",
        "outputId": "4b74a049-ae15-4a3d-c3dc-ef7ac1cc488a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "## Size of the English vocabulary\n",
        "english_corpus = [w for sentence in english_sentences for w in sentence.split()]\n",
        "english_vocab_counter = Counter(english_corpus)\n",
        "english_vocab_size = len(english_vocab_counter)\n",
        "\n",
        "print(\"Size of the English corpus: {}\".format(len(english_corpus)))\n",
        "print(\"Vocab size of English: {}\".format(english_vocab_size))\n",
        "print(\"10 most frequent English vocab: {}\".format([x[0] for x in english_vocab_counter.most_common(10)]))\n",
        "print(\"longest length of sentence: {}\".format(max(len(sentence.split()) for sentence in english_sentences)))\n",
        "print(\"\\n\")\n",
        "\n",
        "## Size of the French vocabulary\n",
        "french_corpus = [w for sentence in french_sentences for w in sentence.split()]\n",
        "french_vocab_counter = Counter(french_corpus)\n",
        "french_vocab_size = len(french_vocab_counter)\n",
        "\n",
        "print(\"Size of the French corpus: {}\".format(len(french_corpus)))\n",
        "print(\"Vocab size of French: {}\".format(french_vocab_size))\n",
        "print(\"10 most frequent French vocab: {}\".format([x[0] for x in french_vocab_counter.most_common(10)]))\n",
        "print(\"longest length of sentence: {}\".format(max(len(sentence.split()) for sentence in french_sentences)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the English corpus: 1823250\n",
            "Vocab size of English: 227\n",
            "10 most frequent English vocab: ['is', ',', '.', 'in', 'it', 'during', 'the', 'but', 'and', 'sometimes']\n",
            "longest length of sentence: 17\n",
            "\n",
            "\n",
            "Size of the French corpus: 1961295\n",
            "Vocab size of French: 355\n",
            "10 most frequent French vocab: ['est', '.', ',', 'en', 'il', 'les', 'mais', 'et', 'la', 'parfois']\n",
            "longest length of sentence: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY0sGS8zh5zU"
      },
      "source": [
        "We see that the longest length of English sentences is 17, and the longest length of French sentences is 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG8n87NYzS97"
      },
      "source": [
        "# Create training, validation, and test datasets\n",
        "\n",
        "We use `sklearn.model_selection.train_test_split` split the dataset (137,861 sentences) into:\n",
        "\n",
        "- training dataset of 120,000 sentences,\n",
        "\n",
        "- validation dataset of 7,861 sentences, and\n",
        "\n",
        "- test dataset of 10,000 sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDggExBWpFAP",
        "outputId": "43cabc82-fb9c-4f87-8640-2872d568bf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "## Split into 120000 training, 7861 validation, and 10000 test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# separate test data\n",
        "X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(english_sentences, french_sentences, test_size = 10000, random_state = 1)\n",
        "\n",
        "# separate train and validation data\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_valid, Y_train_valid, test_size = 7861, random_state = 1)\n",
        "\n",
        "# check sizes\n",
        "print(\"number of training data: {} / {}\".format(len(X_train), len(Y_train)))\n",
        "print(\"number of valid data: {} / {}\".format(len(X_valid), len(Y_valid)))\n",
        "print(\"number of test data: {} / {}\".format(len(X_test), len(Y_test)))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training data: 120000 / 120000\n",
            "number of valid data: 7861 / 7861\n",
            "number of test data: 10000 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxeSECgUdweC"
      },
      "source": [
        "# Build TensorFlow input pipelines\n",
        "\n",
        "Use `tf.data.Dataset.from_tensor_slices` to convert the data into tensorflow dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPSZ0oGQd1oh",
        "outputId": "6260008b-9aa1-4a8a-b2e2-f4dd0cae29c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "\n",
        "next(iter(train_dataset))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'california is usually hot during july , and it is never wet in april .'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'californie est g\\xc3\\xa9n\\xc3\\xa9ralement chaud en juillet , et il est jamais humide en avril .'>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoxNnAtiGqTR"
      },
      "source": [
        "# Tokenize the words\n",
        "\n",
        "We use the method `build_from_corpus` of `tfds.features.text.SubwordTextEncoder` to tokenize the English and French sentences\n",
        "\n",
        "The [SubwordTextEncoder](https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/SubwordTextEncoder) can encode a word by its subwords if that word was not seen in its dictionaty.\n",
        "\n",
        "We specified the `vocab_size` so that the tokens wll give integers from [1, vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhy3L1TMzCgB"
      },
      "source": [
        "## Subword Tokenizer\n",
        "\n",
        "english_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus((eng.numpy() for eng, fr in train_dataset), target_vocab_size = 2**13)\n",
        "french_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus((fr.numpy() for eng, fr in train_dataset), target_vocab_size = 2**13)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6iG_HrZG9hL"
      },
      "source": [
        "The test below will tokenize an English sentence into tokens by the `encode` method of the tokenizer. The token will then be decoded back by using the `decode` method. After decoding we should get the original sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XooacSNgF_uo",
        "outputId": "8f65fb67-e596-4fc2-a6a9-c5c50c0fbc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "## Test the tokenization\n",
        "\n",
        "sample_sentence = X_valid[100]\n",
        "\n",
        "encoded_sample_sentence = english_tokenizer.encode(sample_sentence)\n",
        "\n",
        "print(\"input sentence: {}\".format(sample_sentence))\n",
        "print(\"tokens: {}\".format(encoded_sample_sentence))\n",
        "print(\"tokenized sentence: {}\".format(english_tokenizer.decode(encoded_sample_sentence)))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"detail of tokenizing:\")\n",
        "for k in encoded_sample_sentence:\n",
        "    print(\"{} ---> {}\".format(k, english_tokenizer.decode([k])))\n",
        "\n",
        "print(\"\\n\")\n",
        "## More sanity check on the first 5 sentences in the training dataset\n",
        "for i in range(5):\n",
        "    print(X_train[i] == english_tokenizer.decode(english_tokenizer.encode(X_train[i])))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input sentence: the pear is your most loved fruit , but the grapefruit is her most loved .\n",
            "tokens: [7, 107, 1, 31, 15, 27, 16, 2, 8, 7, 92, 1, 34, 15, 89, 3]\n",
            "tokenized sentence: the pear is your most loved fruit , but the grapefruit is her most loved .\n",
            "\n",
            "\n",
            "detail of tokenizing:\n",
            "7 ---> the \n",
            "107 ---> pear \n",
            "1 ---> is \n",
            "31 ---> your \n",
            "15 ---> most \n",
            "27 ---> loved \n",
            "16 ---> fruit\n",
            "2 --->  , \n",
            "8 ---> but \n",
            "7 ---> the \n",
            "92 ---> grapefruit \n",
            "1 ---> is \n",
            "34 ---> her \n",
            "15 ---> most \n",
            "89 ---> loved\n",
            "3 --->  .\n",
            "\n",
            "\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtH_dC0rHh7V"
      },
      "source": [
        "# The tokenize+pad function\n",
        "\n",
        "The tokenize function takes a list of sentences and its language tokenizer as inputs. It tokenizes the sentences, and add a **start token** and an **end token** in each sentence\n",
        "\n",
        "There are in total N tokens in the tokenizer, with labels from 1 to N-1.\n",
        "\n",
        "We use **N as the start token**, and **N+1 as the end token**.\n",
        "\n",
        "To get N, we use the `vocab_size` attribute of the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7XpTpYtWmE"
      },
      "source": [
        "def tokenize(eng_sentence, fr_sentence):\n",
        "\n",
        "    eng_sentence = [english_tokenizer.vocab_size] + english_tokenizer.encode(eng_sentence.numpy()) + [english_tokenizer.vocab_size+1]\n",
        "    fr_sentence =  [french_tokenizer.vocab_size] + french_tokenizer.encode(fr_sentence.numpy()) + [french_tokenizer.vocab_size+1]\n",
        "\n",
        "    return eng_sentence, fr_sentence\n",
        "\n",
        "\n",
        "def tf_tokenize(eng_sentence, fr_sentence):\n",
        "\n",
        "    res_eng, res_fr = tf.py_function(tokenize, [eng_sentence, fr_sentence], [tf.int64, tf.int64])\n",
        "\n",
        "    res_eng.set_shape([None])\n",
        "    res_fr.set_shape([None])\n",
        "\n",
        "    return res_eng, res_fr\n",
        "\n",
        "\n",
        "def filter_max_length(x, y, max_length = MAX_LENGTH):\n",
        "\n",
        "  return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F14UmedkgUq4"
      },
      "source": [
        "MAX_LENGTH = 25             # maximum length of the input sentence\n",
        "BUFFER_SIZE = 20000         # the size of the shuffle buffer\n",
        "BATCH_SIZE = 64             # the batch size"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMwbCsT83T37"
      },
      "source": [
        "# Propress the training data\n",
        "\n",
        "The code below tokenizes, add SOS & EOS, filter out sentences that are too long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OtHHw2KgaXK"
      },
      "source": [
        "# tokenize the training dataset\n",
        "train_dataset = train_dataset.map(tf_tokenize)\n",
        "# remove sentences that are too long\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the data to memory\n",
        "train_dataset = train_dataset.cache()\n",
        "# shuffle\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "# prefetching\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRUPxfcHgvMo",
        "outputId": "7349b37d-75e0-4b79-cc20-232be7808487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# see a batch\n",
        "eng_batch, fr_batch = next(iter(train_dataset))\n",
        "eng_batch, fr_batch"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 19), dtype=int64, numpy=\n",
              " array([[528,  93,  87, ...,   0,   0,   0],\n",
              "        [528,  28,  72, ...,   0,   0,   0],\n",
              "        [528,  24,   1, ..., 529,   0,   0],\n",
              "        ...,\n",
              "        [528,  33,  15, ...,   0,   0,   0],\n",
              "        [528,  21,   1, ...,   0,   0,   0],\n",
              "        [528,   7, 115, ...,   3, 529,   0]])>,\n",
              " <tf.Tensor: shape=(64, 23), dtype=int64, numpy=\n",
              " array([[717, 141, 571, ...,   0,   0,   0],\n",
              "        [717,  30,  29, ...,   0,   0,   0],\n",
              "        [717,   9,  35, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [717, 190, 162, ...,   0,   0,   0],\n",
              "        [717, 569,  10, ...,   0,   0,   0],\n",
              "        [717, 569, 500, ...,   0,   0,   0]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP6NKeHO-g8q"
      },
      "source": [
        "# Preprocess the validation data\n",
        "\n",
        "We put all the validation data into a single tensor. We evaluate the model on validation data after a complete episode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXkEs_AC-fPM"
      },
      "source": [
        "## validation data preprocessing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXVwNDf1sC8I"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPj2SLAHm9WX"
      },
      "source": [
        "num_layers = 6       # number of layers (original paper used 6)\n",
        "d_model = 512        # dimension of embedding (original paper used 512)\n",
        "ff_units = 512       # number of units used in the position-wise feed-forward networks (original paper used 2048)\n",
        "num_heads = 8        # number of heads in the multi-head attention  (original paper used 8)\n",
        "\n",
        "dropout_rate = 0.1   # the rate of dropout (original paper used 0.1)\n",
        "\n",
        "input_vocab_size = english_tokenizer.vocab_size + 2\n",
        "output_vocab_size = french_tokenizer.vocab_size + 2"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfsHuDADzeTL"
      },
      "source": [
        "# Positional Encoding\n",
        "\n",
        "Positional encoding enables the input word to carry information about it's spatial location in the input sentence.\n",
        "\n",
        "Positional encoding is performed after the input sentence was passed through the embedding layer, with the shape (batch_size, d_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxzIVtlBzHbp"
      },
      "source": [
        "def get_PE_angle(pos, i, d_model):\n",
        "    \"\"\"\n",
        "    Calculate the angle used in the positional encoding. The equations:\n",
        "\n",
        "    PE_angle(pos, 2k) = pos/10000**(2k/d_model)     if i is even, i = 2*k ; if i is odd, i = 2*k + 1\n",
        "\n",
        "    inputs:\n",
        "            pos: the position\n",
        "            i: the dimension\n",
        "            d_model: embedding dimension\n",
        "    \n",
        "    output:\n",
        "            PE_angle: the PE angle \n",
        "    \"\"\"\n",
        "\n",
        "    k = i // 2\n",
        "    denominator = np.power(10000, 2*k/np.float32(d_model))\n",
        "    PE_angle = pos / denominator\n",
        "\n",
        "    return PE_angle\n",
        "\n",
        "\n",
        "def Positional_Encoding(num_positions, d_model):\n",
        "    \"\"\"\n",
        "    Calculate the positional encoding vector\n",
        "\n",
        "    PE(pos, 2k) = sin(pos/10000**(2k/d_model))     if i is even, i = 2*k\n",
        "    PE(pos, 2k+1) = cos(pos/10000**(2k/d_model))   if i is odd,  i = 2*k + 1\n",
        "\n",
        "    inputs:\n",
        "            num_positions: number of positions\n",
        "            d_model: embedding dimension\n",
        "    \"\"\"\n",
        "\n",
        "    PE_angles = get_PE_angle(pos = np.arange(num_positions)[:, np.newaxis], # shape (num_positions, 1)\n",
        "                             i = np.arange(d_model)[np.newaxis, :],         # shape (1, d_model)\n",
        "                             d_model = d_model)\n",
        "    \n",
        "    ## after broadcasting, PE_angles has the shape (num_positions, d_model)\n",
        "    assert PE_angles.shape == (num_positions, d_model)\n",
        "\n",
        "    # odd indeces\n",
        "    PE_angles[:, 1::2] = np.cos(PE_angles[:, 1::2])\n",
        "\n",
        "    # even indeces\n",
        "    PE_angles[:, 0::2] = np.sin(PE_angles[:, 0::2])\n",
        "\n",
        "    # append a new dimention\n",
        "    res = PE_angles[np.newaxis, ...] # shape (1, num_positions, d_model)\n",
        "\n",
        "    return tf.cast(res, dtype = tf.float32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBrDnF1Mp-r5"
      },
      "source": [
        "#Padding Mask\n",
        "\n",
        "Masking will be performed on padded zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYS_RQcNqOr4"
      },
      "source": [
        "## Masking on padded zeros\n",
        "\n",
        "def create_padding_mask(x):\n",
        "    \"\"\"\n",
        "    Create a tensor of booleans, the value is 1 if there's a padded zero. The value is 0 is it is not zero.\n",
        "\n",
        "    input\n",
        "            x: the input vector\n",
        "    \n",
        "    output\n",
        "            padding_mask (dtype = tf.float32)\n",
        "    \"\"\"\n",
        "\n",
        "    padding_boolean = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "\n",
        "    padding_mask = padding_boolean[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, sentence_length)\n",
        "\n",
        "    return padding_mask"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m7q-Fx-rUHK"
      },
      "source": [
        "# Look-ahead mask\n",
        "\n",
        "This mask masks the future tokens\n",
        "\n",
        "The code uses `tf.linalg.band_part` to set values outside the band to be 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcHzqrUGrdIA"
      },
      "source": [
        "def create_lookahead_mask(size):\n",
        "\n",
        "    lookahead_mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "\n",
        "    return lookahead_mask"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGej8AGcsprz"
      },
      "source": [
        "# Scaled Dot-Product Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZvjGu_J4_GT"
      },
      "source": [
        "def SDP_Attention(Q, K, V, mask):\n",
        "    \"\"\"\n",
        "    Calculate the weights of the scaled dot product attention\n",
        "    Equation: SDP_Attention(Q, K, V, mask) = softmax_k(Q transpose(K) / sqrt(d_k)) <matmul>  V\n",
        "\n",
        "    inputs:\n",
        "            Q - query\n",
        "            K - key\n",
        "            V - value\n",
        "            mask - mask\n",
        "\n",
        "    outputs:\n",
        "            SDP_attention - softmax_k(Q transpose(K) / sqrt(d_k)) <matmul>  V\n",
        "            weights       - softmax_k(Q transpose(K) / sqrt(d_k))\n",
        "    \"\"\"\n",
        "\n",
        "    QK = tf.matmul(Q, K, transpose_b = True)\n",
        "\n",
        "    # calculate d_k\n",
        "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
        "\n",
        "    # logits\n",
        "    logits = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "    # mask\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # calculate weights\n",
        "    W = tf.nn.softmax(logits, axis = -1)\n",
        "\n",
        "    return tf.matmul(W, V), W\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqJ16ehY0Mda"
      },
      "source": [
        "# Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_I3Ird50MBi"
      },
      "source": [
        "class MHA(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, d_model, num_heads):\n",
        "\n",
        "        super(MHA, self).__init__()\n",
        "\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.dense_Q = tf.keras.layers.Dense(d_model)\n",
        "        self.dense_K = tf.keras.layers.Dense(d_model)\n",
        "        self.dense_V = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense_out = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        split the last dimension into (self.num_heads, self.depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "\n",
        "        return tf.transpose(x, perm = [0, 2, 1, 3])\n",
        "\n",
        "\n",
        "    def call(self, V, K, Q, mask):\n",
        "        \n",
        "        batch_size = tf.shape(Q)[0]\n",
        "\n",
        "        V = self.dense_V(V)\n",
        "        K = self.dense_K(K)\n",
        "        Q = self.dense_Q(Q)\n",
        "\n",
        "        V = self.split_heads(V, batch_size)\n",
        "        K = self.split_heads(K, batch_size)\n",
        "        Q = self.split_heads(Q, batch_size)\n",
        "        \n",
        "        scaled_attention, attention_weights = SDP_Attention(Q, K, V, mask) # args: Q, K, V, mask\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "        output = self.dense_out(concat_attention)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbUd2-_g4Etj"
      },
      "source": [
        "# Point wise feed forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfK1qjaT30xl"
      },
      "source": [
        "def Point_Wise_Feed_Forward(d_model, ff_units):\n",
        "\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Dense(ff_units, activation = 'relu'),\n",
        "                                 tf.keras.layers.Dense(d_model)])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I09zUHew54Hp"
      },
      "source": [
        "# Encoder Layer\n",
        "\n",
        "The encoder block contains:\n",
        "\n",
        "1. Multi-Head Attention\n",
        "2. Add residual and normalize\n",
        "3. Point-wise feed forward\n",
        "4. Add residual and normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKslJe7j42Uk"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, ff_units, dropout_rate = 0.1):\n",
        "\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.MHA = MHA(d_model, num_heads)\n",
        "        self.FF = Point_Wise_Feed_Forward(d_model, ff_units)\n",
        "\n",
        "        self.Norm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.Norm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "\n",
        "        self.Dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.Dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, training_bool, mask):\n",
        "\n",
        "        attention, _ = self.MHA(x, x, x, mask)\n",
        "        attention = self.Dropout1(attention, training = training_bool)\n",
        "        \n",
        "        y = self.Norm1(x + attention)\n",
        "\n",
        "        ff = self.FF(y)\n",
        "        ff = self.Dropout2(ff, training = training_bool)\n",
        "\n",
        "        output = self.Norm2(y + ff)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-xmEKUgF8Bc"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wOgqhn6_rpL"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, num_layers, d_model, num_heads, ff_units, input_vocab_size, max_position_encoding, dropout_rate = 0.1):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.Embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.PositionalEncoding = Positional_Encoding(max_position_encoding, d_model)\n",
        "\n",
        "        self.EncoderLayers = [EncoderLayer(d_model, num_heads, ff_units, dropout_rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.Dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.Embedding(x)\n",
        "\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, dtype = tf.float32))\n",
        "\n",
        "        x += self.PositionalEncoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.Dropout(x, training = training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.EncoderLayers[i](x, training, mask)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHHRSPJp81SM"
      },
      "source": [
        "# Decoder Layer\n",
        "\n",
        "1. MHA\n",
        "2. Add residual and norm\n",
        "3. MHA (V = K = output_from_encoder_block, Q = output_from_2)\n",
        "4. add residual (output_from_2) and norm\n",
        "5. feed forward\n",
        "6. add residual and norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlYyEL708rZX"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, ff_units, dropout_rate = 0.1):\n",
        "\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.MHA1 = MHA(d_model, num_heads)\n",
        "        self.MHA2 = MHA(d_model, num_heads)\n",
        "\n",
        "        self.FF = Point_Wise_Feed_Forward(d_model, ff_units)\n",
        "\n",
        "        self.Dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.Dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.Dropout3 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.Norm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.Norm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.Norm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        \n",
        "\n",
        "    def call(self, x, encoder_output, training_bool, look_ahead_mask, padding_mask):\n",
        "\n",
        "        attention_1, attention_weights_1 = self.MHA1(x, x, x, look_ahead_mask)\n",
        "        attention_1 = self.Dropout1(attention_1, training = training_bool)\n",
        "        y1 = self.Norm1(attention_1 + x)\n",
        "\n",
        "        attention_2, attention_weights_2 = self.MHA2(encoder_output, encoder_output, y1, padding_mask)\n",
        "        attention_2 = self.Dropout2(attention_2, training = training_bool)\n",
        "        y2 = self.Norm2(attention_2 + y1)\n",
        "        \n",
        "        ff = self.FF(y2)\n",
        "        ff = self.Dropout3(ff, training = training_bool)\n",
        "        y3 = self.Norm3(ff + y2)\n",
        "        \n",
        "        return y3, attention_weights_1, attention_weights_2"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ij2PNHDI3uB"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHNs-oEBIwqz"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, num_layers, d_model, num_heads, ff_units, output_vocab_size, max_position_encoding, dropout_rate = 0.1):\n",
        "\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # embedding layer\n",
        "        self.Embedding = tf.keras.layers.Embedding(output_vocab_size, d_model)\n",
        "        # positional encoding\n",
        "        self.PositionalEncoding = Positional_Encoding(max_position_encoding, d_model)\n",
        "        # dropout\n",
        "        self.Dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        # decode layers\n",
        "        self.DecodeLayers = [DecoderLayer(d_model, num_heads, ff_units, dropout_rate) for _ in range(num_layers)]\n",
        "\n",
        "\n",
        "    def call(self, x, encoder_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        attention_weights = {}\n",
        "\n",
        "        # embedding\n",
        "        x = self.Embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        # positional encoding\n",
        "        x += self.PositionalEncoding[:, :seq_len, :]\n",
        "        # dropout\n",
        "        x = self.Dropout(x, training = training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "\n",
        "            x, aw1, aw2 = self.DecodeLayers[i](x, encoder_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights[\"AW1_{}\".format(i+1)] = aw1\n",
        "            attention_weights[\"AW2_{}\".format(i+1)] = aw2\n",
        "        \n",
        "        return x, attention_weights"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2whNsbPK-pd"
      },
      "source": [
        "# Build Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIgsrnhBKtII"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_layers, d_model, num_heads, ff_units, input_vocab_size, output_vocab_size, pe_input, pe_target, dropout_rate = 0.1):\n",
        "\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.Encoder = Encoder(num_layers, d_model, num_heads, ff_units, input_vocab_size, pe_input, dropout_rate)\n",
        "        self.Decoder = Decoder(num_layers, d_model, num_heads, ff_units, output_vocab_size, pe_target, dropout_rate)\n",
        "        self.Dense = tf.keras.layers.Dense(output_vocab_size)\n",
        "\n",
        "    def call(self, x, y, training, encoder_padding_mask, look_ahead_mask, decoder_padding_mask):\n",
        "\n",
        "        encoder_output = self.Encoder(x, training, encoder_padding_mask)\n",
        "\n",
        "        decoder_output, attention_weights = self.Decoder(y, encoder_output, training, look_ahead_mask, decoder_padding_mask)\n",
        "\n",
        "        final_output = self.Dense(decoder_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3g_iCVFnfzc"
      },
      "source": [
        "# Optimizer with scheduled learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns5R41b0nlKz",
        "outputId": "86ba5671-155c-4e45-98f5-9f4362112966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "class Scheduled_LR(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps = 4000):\n",
        "\n",
        "        super(Scheduled_LR, self).__init__()\n",
        "\n",
        "\n",
        "        # cast the parameters to tf.float32 in order to use tf.math.rsqrt() function later\n",
        "        self.d_model = tf.cast(d_model, dtype = tf.float32)\n",
        "        self.warmup_steps = tf.cast(warmup_steps, dtype = tf.float32)\n",
        "\n",
        "    def __call__(self, step_num):\n",
        "        \"\"\"\n",
        "        Determine the learning rate at step = t\n",
        "\n",
        "        lrate = rsqrt(d_model)*min(rsqrt(step_num), step_num*rsqrt(warmup_steps**3))\n",
        "        \"\"\"\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(tf.math.rsqrt(step_num), step_num*tf.math.rsqrt(self.warmup_steps**3))\n",
        "\n",
        "\n",
        "# Plot the learning rate\n",
        "temp_learning_rate_schedule = Scheduled_LR(d_model = 128)\n",
        "\n",
        "lr = temp_learning_rate_schedule(tf.range(40000, dtype = tf.float32))\n",
        "\n",
        "plt.plot(lr)\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")\n",
        "\n",
        "\n",
        "## Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = Scheduled_LR(d_model), beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDzv9dL4sGoL"
      },
      "source": [
        "# Loss and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpA9eXOpsSa0"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
        "\n",
        "def loss_function(real, prediction):\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_  = loss_object(real, prediction)\n",
        "\n",
        "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
        "    loss_  *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_acc')"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ift4yhkBtIRR"
      },
      "source": [
        "# Helper function to create masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsp0ikNmtdu-"
      },
      "source": [
        "def create_masks(input, target):\n",
        "\n",
        "    # padding masks\n",
        "    encoder_padding_mask = create_padding_mask(input)\n",
        "    decoder_padding_mask = create_padding_mask(input)\n",
        "\n",
        "    # lookahead mask\n",
        "    lookahead_mask = create_lookahead_mask(tf.shape(target)[1])\n",
        "    decoder_target_padding_mask = create_padding_mask(target)\n",
        "    combined_mask = tf.maximum(lookahead_mask, decoder_target_padding_mask)\n",
        "\n",
        "    return encoder_padding_mask, combined_mask, decoder_padding_mask"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw69nL74yKFc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMGoQLgHylnC"
      },
      "source": [
        "train_step_signature = [tf.TensorSpec(shape=(None, None), dtype = tf.int64), tf.TensorSpec(shape=(None, None), dtype = tf.int64)]\n",
        "\n",
        "@tf.function(input_signature = train_step_signature)\n",
        "def train_step(input, target):\n",
        "    target_input = target[:, :-1]\n",
        "    target_real = target[:, 1:]\n",
        "\n",
        "    encoder_padding_mask, combined_mask, decoder_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        # arguments of transformer: x, y, training_bool, encoder_padding_mask, look_ahead_mask, decoder_padding_mask\n",
        "        predictions, _ = transformer(x = input,\n",
        "                                    y = target_input,\n",
        "                                    training = True,\n",
        "                                    encoder_padding_mask = encoder_padding_mask,\n",
        "                                    look_ahead_mask = combined_mask,\n",
        "                                    decoder_padding_mask = decoder_padding_mask)\n",
        "\n",
        "        loss = loss_function(target_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_acc(target_real, predictions)\n"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uBpS6CNy6y6",
        "outputId": "fa9fad82-d320-4311-f878-d1c4aba432b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "\n",
        "## create the transformer\n",
        "transformer = Transformer(num_layers, d_model, num_heads, ff_units, input_vocab_size, output_vocab_size, input_vocab_size, output_vocab_size, dropout_rate = 0.1)\n",
        "\n",
        "for epoch in range(EPOCHS+1):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_acc.reset_states()\n",
        "\n",
        "    for (batch, (input, target)) in enumerate(train_dataset):\n",
        "\n",
        "        train_step(input, target)\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f} Acc {:.4f}'.format(epoch, batch, train_loss.result(), train_acc.result()))\n",
        "    \n",
        "\n",
        "    print('Epoch {} Loss {:.4f} Acc {:.4f}'.format(epoch, train_loss.result(), train_acc.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 0 Loss 6.9463 Acc 0.0028\n",
            "Epoch 0 Batch 100 Loss 5.4884 Acc 0.0506\n",
            "Epoch 0 Batch 200 Loss 4.6264 Acc 0.1108\n",
            "Epoch 0 Batch 300 Loss 3.7902 Acc 0.2070\n",
            "Epoch 0 Batch 400 Loss 3.1575 Acc 0.2822\n",
            "Epoch 0 Batch 500 Loss 2.7018 Acc 0.3373\n",
            "Epoch 0 Batch 600 Loss 2.3610 Acc 0.3795\n",
            "Epoch 0 Batch 700 Loss 2.1002 Acc 0.4120\n",
            "Epoch 0 Batch 800 Loss 1.8950 Acc 0.4384\n",
            "Epoch 0 Batch 900 Loss 1.7282 Acc 0.4606\n",
            "Epoch 0 Batch 1000 Loss 1.5902 Acc 0.4795\n",
            "Epoch 0 Batch 1100 Loss 1.4735 Acc 0.4958\n",
            "Epoch 0 Batch 1200 Loss 1.3746 Acc 0.5097\n",
            "Epoch 0 Batch 1300 Loss 1.2896 Acc 0.5220\n",
            "Epoch 0 Batch 1400 Loss 1.2155 Acc 0.5322\n",
            "Epoch 0 Batch 1500 Loss 1.1501 Acc 0.5416\n",
            "Epoch 0 Batch 1600 Loss 1.0925 Acc 0.5501\n",
            "Epoch 0 Batch 1700 Loss 1.0414 Acc 0.5572\n",
            "Epoch 0 Batch 1800 Loss 0.9954 Acc 0.5638\n",
            "Epoch 0 Loss 0.9639 Acc 0.5684\n",
            "Time taken for 1 epoch: 160.63922953605652 secs\n",
            "\n",
            "Epoch 1 Batch 0 Loss 0.1839 Acc 0.7031\n",
            "Epoch 1 Batch 100 Loss 0.1948 Acc 0.6869\n",
            "Epoch 1 Batch 200 Loss 0.1959 Acc 0.6828\n",
            "Epoch 1 Batch 300 Loss 0.1924 Acc 0.6818\n",
            "Epoch 1 Batch 400 Loss 0.1905 Acc 0.6817\n",
            "Epoch 1 Batch 500 Loss 0.1885 Acc 0.6820\n",
            "Epoch 1 Batch 600 Loss 0.1864 Acc 0.6821\n",
            "Epoch 1 Batch 700 Loss 0.1852 Acc 0.6817\n",
            "Epoch 1 Batch 800 Loss 0.1843 Acc 0.6820\n",
            "Epoch 1 Batch 900 Loss 0.1830 Acc 0.6824\n",
            "Epoch 1 Batch 1000 Loss 0.1819 Acc 0.6827\n",
            "Epoch 1 Batch 1100 Loss 0.1808 Acc 0.6829\n",
            "Epoch 1 Batch 1200 Loss 0.1800 Acc 0.6833\n",
            "Epoch 1 Batch 1300 Loss 0.1796 Acc 0.6833\n",
            "Epoch 1 Batch 1400 Loss 0.1790 Acc 0.6834\n",
            "Epoch 1 Batch 1500 Loss 0.1799 Acc 0.6830\n",
            "Epoch 1 Batch 1600 Loss 0.1781 Acc 0.6832\n",
            "Epoch 1 Batch 1700 Loss 0.1792 Acc 0.6828\n",
            "Epoch 1 Batch 1800 Loss 0.1787 Acc 0.6834\n",
            "Epoch 1 Loss 0.1785 Acc 0.6836\n",
            "Time taken for 1 epoch: 141.239586353302 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2517 Acc 0.6853\n",
            "Epoch 2 Batch 100 Loss 0.1764 Acc 0.6863\n",
            "Epoch 2 Batch 200 Loss 0.1924 Acc 0.6819\n",
            "Epoch 2 Batch 300 Loss 0.1924 Acc 0.6833\n",
            "Epoch 2 Batch 400 Loss 0.1879 Acc 0.6835\n",
            "Epoch 2 Batch 500 Loss 0.1892 Acc 0.6838\n",
            "Epoch 2 Batch 600 Loss 0.1829 Acc 0.6842\n",
            "Epoch 2 Batch 700 Loss 0.1854 Acc 0.6833\n",
            "Epoch 2 Batch 800 Loss 0.1828 Acc 0.6836\n",
            "Epoch 2 Batch 900 Loss 0.1807 Acc 0.6838\n",
            "Epoch 2 Batch 1000 Loss 0.1832 Acc 0.6830\n",
            "Epoch 2 Batch 1100 Loss 0.1784 Acc 0.6845\n",
            "Epoch 2 Batch 1200 Loss 0.1824 Acc 0.6835\n",
            "Epoch 2 Batch 1300 Loss 0.1780 Acc 0.6843\n",
            "Epoch 2 Batch 1400 Loss 0.1753 Acc 0.6851\n",
            "Epoch 2 Batch 1500 Loss 0.1734 Acc 0.6857\n",
            "Epoch 2 Batch 1600 Loss 0.1753 Acc 0.6853\n",
            "Epoch 2 Batch 1700 Loss 0.1737 Acc 0.6859\n",
            "Epoch 2 Batch 1800 Loss 0.1727 Acc 0.6859\n",
            "Epoch 2 Loss 0.1771 Acc 0.6852\n",
            "Time taken for 1 epoch: 141.00139498710632 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.2917 Acc 0.6525\n",
            "Epoch 3 Batch 100 Loss 0.3876 Acc 0.6425\n",
            "Epoch 3 Batch 200 Loss 0.3874 Acc 0.6399\n",
            "Epoch 3 Batch 300 Loss 0.3140 Acc 0.6549\n",
            "Epoch 3 Batch 400 Loss 0.2824 Acc 0.6618\n",
            "Epoch 3 Batch 500 Loss 0.2656 Acc 0.6653\n",
            "Epoch 3 Batch 600 Loss 0.2544 Acc 0.6681\n",
            "Epoch 3 Batch 700 Loss 0.2477 Acc 0.6699\n",
            "Epoch 3 Batch 800 Loss 0.2425 Acc 0.6712\n",
            "Epoch 3 Batch 900 Loss 0.2360 Acc 0.6724\n",
            "Epoch 3 Batch 1000 Loss 0.2325 Acc 0.6732\n",
            "Epoch 3 Batch 1100 Loss 0.2323 Acc 0.6732\n",
            "Epoch 3 Batch 1200 Loss 0.2304 Acc 0.6736\n",
            "Epoch 3 Batch 1300 Loss 0.2321 Acc 0.6733\n",
            "Epoch 3 Batch 1400 Loss 0.2298 Acc 0.6740\n",
            "Epoch 3 Batch 1500 Loss 0.2269 Acc 0.6744\n",
            "Epoch 3 Batch 1600 Loss 0.2229 Acc 0.6754\n",
            "Epoch 3 Batch 1700 Loss 0.2211 Acc 0.6758\n",
            "Epoch 3 Batch 1800 Loss 0.2180 Acc 0.6764\n",
            "Epoch 3 Loss 0.2175 Acc 0.6767\n",
            "Time taken for 1 epoch: 139.92673563957214 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1115 Acc 0.7269\n",
            "Epoch 4 Batch 100 Loss 0.1335 Acc 0.6958\n",
            "Epoch 4 Batch 200 Loss 0.1215 Acc 0.7008\n",
            "Epoch 4 Batch 300 Loss 0.1286 Acc 0.6962\n",
            "Epoch 4 Batch 400 Loss 0.1313 Acc 0.6943\n",
            "Epoch 4 Batch 500 Loss 0.1284 Acc 0.6955\n",
            "Epoch 4 Batch 600 Loss 0.1284 Acc 0.6957\n",
            "Epoch 4 Batch 700 Loss 0.1252 Acc 0.6961\n",
            "Epoch 4 Batch 800 Loss 0.1219 Acc 0.6972\n",
            "Epoch 4 Batch 900 Loss 0.1223 Acc 0.6973\n",
            "Epoch 4 Batch 1000 Loss 0.1257 Acc 0.6962\n",
            "Epoch 4 Batch 1100 Loss 0.1234 Acc 0.6964\n",
            "Epoch 4 Batch 1200 Loss 0.1261 Acc 0.6958\n",
            "Epoch 4 Batch 1300 Loss 0.1244 Acc 0.6965\n",
            "Epoch 4 Batch 1400 Loss 0.1225 Acc 0.6973\n",
            "Epoch 4 Batch 1500 Loss 0.1228 Acc 0.6970\n",
            "Epoch 4 Batch 1600 Loss 0.1198 Acc 0.6979\n",
            "Epoch 4 Batch 1700 Loss 0.1178 Acc 0.6985\n",
            "Epoch 4 Batch 1800 Loss 0.1160 Acc 0.6986\n",
            "Epoch 4 Loss 0.1145 Acc 0.6988\n",
            "Time taken for 1 epoch: 137.90562295913696 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0414 Acc 0.7440\n",
            "Epoch 5 Batch 100 Loss 0.0763 Acc 0.7091\n",
            "Epoch 5 Batch 200 Loss 0.0748 Acc 0.7070\n",
            "Epoch 5 Batch 300 Loss 0.0773 Acc 0.7061\n",
            "Epoch 5 Batch 400 Loss 0.0862 Acc 0.7044\n",
            "Epoch 5 Batch 500 Loss 0.0819 Acc 0.7053\n",
            "Epoch 5 Batch 600 Loss 0.0825 Acc 0.7060\n",
            "Epoch 5 Batch 700 Loss 0.0840 Acc 0.7058\n",
            "Epoch 5 Batch 800 Loss 0.0814 Acc 0.7066\n",
            "Epoch 5 Batch 900 Loss 0.0800 Acc 0.7066\n",
            "Epoch 5 Batch 1000 Loss 0.0787 Acc 0.7065\n",
            "Epoch 5 Batch 1100 Loss 0.0774 Acc 0.7065\n",
            "Epoch 5 Batch 1200 Loss 0.0778 Acc 0.7059\n",
            "Epoch 5 Batch 1300 Loss 0.0779 Acc 0.7061\n",
            "Epoch 5 Batch 1400 Loss 0.0770 Acc 0.7064\n",
            "Epoch 5 Batch 1500 Loss 0.0758 Acc 0.7067\n",
            "Epoch 5 Batch 1600 Loss 0.0752 Acc 0.7070\n",
            "Epoch 5 Batch 1700 Loss 0.0745 Acc 0.7073\n",
            "Epoch 5 Batch 1800 Loss 0.0792 Acc 0.7067\n",
            "Epoch 5 Loss 0.0789 Acc 0.7069\n",
            "Time taken for 1 epoch: 138.2266707420349 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0413 Acc 0.7124\n",
            "Epoch 6 Batch 100 Loss 0.0549 Acc 0.7096\n",
            "Epoch 6 Batch 200 Loss 0.0600 Acc 0.7103\n",
            "Epoch 6 Batch 300 Loss 0.0613 Acc 0.7079\n",
            "Epoch 6 Batch 400 Loss 0.0604 Acc 0.7091\n",
            "Epoch 6 Batch 500 Loss 0.0622 Acc 0.7093\n",
            "Epoch 6 Batch 600 Loss 0.0611 Acc 0.7096\n",
            "Epoch 6 Batch 700 Loss 0.0602 Acc 0.7103\n",
            "Epoch 6 Batch 800 Loss 0.0599 Acc 0.7105\n",
            "Epoch 6 Batch 900 Loss 0.0606 Acc 0.7103\n",
            "Epoch 6 Batch 1000 Loss 0.0605 Acc 0.7100\n",
            "Epoch 6 Batch 1100 Loss 0.0597 Acc 0.7108\n",
            "Epoch 6 Batch 1200 Loss 0.0595 Acc 0.7103\n",
            "Epoch 6 Batch 1300 Loss 0.0591 Acc 0.7102\n",
            "Epoch 6 Batch 1400 Loss 0.0595 Acc 0.7101\n",
            "Epoch 6 Batch 1500 Loss 0.0596 Acc 0.7107\n",
            "Epoch 6 Batch 1600 Loss 0.0589 Acc 0.7108\n",
            "Epoch 6 Batch 1700 Loss 0.0585 Acc 0.7109\n",
            "Epoch 6 Batch 1800 Loss 0.0585 Acc 0.7108\n",
            "Epoch 6 Loss 0.0583 Acc 0.7108\n",
            "Time taken for 1 epoch: 138.5358760356903 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0440 Acc 0.7560\n",
            "Epoch 7 Batch 100 Loss 0.0516 Acc 0.7145\n",
            "Epoch 7 Batch 200 Loss 0.0596 Acc 0.7105\n",
            "Epoch 7 Batch 300 Loss 0.0560 Acc 0.7132\n",
            "Epoch 7 Batch 400 Loss 0.0538 Acc 0.7136\n",
            "Epoch 7 Batch 500 Loss 0.0566 Acc 0.7132\n",
            "Epoch 7 Batch 600 Loss 0.0558 Acc 0.7133\n",
            "Epoch 7 Batch 700 Loss 0.0550 Acc 0.7127\n",
            "Epoch 7 Batch 800 Loss 0.0557 Acc 0.7128\n",
            "Epoch 7 Batch 900 Loss 0.0555 Acc 0.7128\n",
            "Epoch 7 Batch 1000 Loss 0.0557 Acc 0.7127\n",
            "Epoch 7 Batch 1100 Loss 0.0556 Acc 0.7128\n",
            "Epoch 7 Batch 1200 Loss 0.0550 Acc 0.7126\n",
            "Epoch 7 Batch 1300 Loss 0.0546 Acc 0.7127\n",
            "Epoch 7 Batch 1400 Loss 0.0541 Acc 0.7124\n",
            "Epoch 7 Batch 1500 Loss 0.0538 Acc 0.7129\n",
            "Epoch 7 Batch 1600 Loss 0.0533 Acc 0.7130\n",
            "Epoch 7 Batch 1700 Loss 0.0535 Acc 0.7127\n",
            "Epoch 7 Batch 1800 Loss 0.0529 Acc 0.7128\n",
            "Epoch 7 Loss 0.0523 Acc 0.7131\n",
            "Time taken for 1 epoch: 137.62375116348267 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0473 Acc 0.6705\n",
            "Epoch 8 Batch 100 Loss 0.0468 Acc 0.7109\n",
            "Epoch 8 Batch 200 Loss 0.0554 Acc 0.7117\n",
            "Epoch 8 Batch 300 Loss 0.0514 Acc 0.7133\n",
            "Epoch 8 Batch 400 Loss 0.0501 Acc 0.7124\n",
            "Epoch 8 Batch 500 Loss 0.0491 Acc 0.7124\n",
            "Epoch 8 Batch 600 Loss 0.0480 Acc 0.7127\n",
            "Epoch 8 Batch 700 Loss 0.0479 Acc 0.7129\n",
            "Epoch 8 Batch 800 Loss 0.0468 Acc 0.7132\n",
            "Epoch 8 Batch 900 Loss 0.0470 Acc 0.7130\n",
            "Epoch 8 Batch 1000 Loss 0.0460 Acc 0.7133\n",
            "Epoch 8 Batch 1100 Loss 0.0453 Acc 0.7133\n",
            "Epoch 8 Batch 1200 Loss 0.0447 Acc 0.7140\n",
            "Epoch 8 Batch 1300 Loss 0.0443 Acc 0.7146\n",
            "Epoch 8 Batch 1400 Loss 0.0439 Acc 0.7149\n",
            "Epoch 8 Batch 1500 Loss 0.0441 Acc 0.7149\n",
            "Epoch 8 Batch 1600 Loss 0.0438 Acc 0.7148\n",
            "Epoch 8 Batch 1700 Loss 0.0436 Acc 0.7147\n",
            "Epoch 8 Batch 1800 Loss 0.0432 Acc 0.7150\n",
            "Epoch 8 Loss 0.0438 Acc 0.7152\n",
            "Time taken for 1 epoch: 139.36506867408752 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0667 Acc 0.7225\n",
            "Epoch 9 Batch 100 Loss 0.0405 Acc 0.7156\n",
            "Epoch 9 Batch 200 Loss 0.0414 Acc 0.7143\n",
            "Epoch 9 Batch 300 Loss 0.0399 Acc 0.7141\n",
            "Epoch 9 Batch 400 Loss 0.0403 Acc 0.7141\n",
            "Epoch 9 Batch 500 Loss 0.0435 Acc 0.7147\n",
            "Epoch 9 Batch 600 Loss 0.0440 Acc 0.7146\n",
            "Epoch 9 Batch 700 Loss 0.0438 Acc 0.7153\n",
            "Epoch 9 Batch 800 Loss 0.0432 Acc 0.7153\n",
            "Epoch 9 Batch 900 Loss 0.0433 Acc 0.7152\n",
            "Epoch 9 Batch 1000 Loss 0.0452 Acc 0.7144\n",
            "Epoch 9 Batch 1100 Loss 0.0452 Acc 0.7149\n",
            "Epoch 9 Batch 1200 Loss 0.0454 Acc 0.7146\n",
            "Epoch 9 Batch 1300 Loss 0.0459 Acc 0.7145\n",
            "Epoch 9 Batch 1400 Loss 0.0452 Acc 0.7147\n",
            "Epoch 9 Batch 1500 Loss 0.0450 Acc 0.7150\n",
            "Epoch 9 Batch 1600 Loss 0.0443 Acc 0.7151\n",
            "Epoch 9 Batch 1700 Loss 0.0448 Acc 0.7148\n",
            "Epoch 9 Batch 1800 Loss 0.0443 Acc 0.7150\n",
            "Epoch 9 Loss 0.0442 Acc 0.7148\n",
            "Time taken for 1 epoch: 140.28591465950012 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0294 Acc 0.7930\n",
            "Epoch 10 Batch 100 Loss 0.0395 Acc 0.7102\n",
            "Epoch 10 Batch 200 Loss 0.0382 Acc 0.7133\n",
            "Epoch 10 Batch 300 Loss 0.0374 Acc 0.7151\n",
            "Epoch 10 Batch 400 Loss 0.0366 Acc 0.7155\n",
            "Epoch 10 Batch 500 Loss 0.0362 Acc 0.7172\n",
            "Epoch 10 Batch 600 Loss 0.0367 Acc 0.7171\n",
            "Epoch 10 Batch 700 Loss 0.0361 Acc 0.7166\n",
            "Epoch 10 Batch 800 Loss 0.0361 Acc 0.7166\n",
            "Epoch 10 Batch 900 Loss 0.0360 Acc 0.7170\n",
            "Epoch 10 Batch 1000 Loss 0.0359 Acc 0.7166\n",
            "Epoch 10 Batch 1100 Loss 0.0360 Acc 0.7165\n",
            "Epoch 10 Batch 1200 Loss 0.0357 Acc 0.7168\n",
            "Epoch 10 Batch 1300 Loss 0.0354 Acc 0.7169\n",
            "Epoch 10 Batch 1400 Loss 0.0356 Acc 0.7167\n",
            "Epoch 10 Batch 1500 Loss 0.0353 Acc 0.7168\n",
            "Epoch 10 Batch 1600 Loss 0.0353 Acc 0.7167\n",
            "Epoch 10 Batch 1700 Loss 0.0421 Acc 0.7155\n",
            "Epoch 10 Batch 1800 Loss 0.0436 Acc 0.7153\n",
            "Epoch 10 Loss 0.0439 Acc 0.7152\n",
            "Time taken for 1 epoch: 139.7928376197815 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.0301 Acc 0.7589\n",
            "Epoch 11 Batch 100 Loss 0.0376 Acc 0.7128\n",
            "Epoch 11 Batch 200 Loss 0.0386 Acc 0.7118\n",
            "Epoch 11 Batch 300 Loss 0.0365 Acc 0.7131\n",
            "Epoch 11 Batch 400 Loss 0.0365 Acc 0.7140\n",
            "Epoch 11 Batch 500 Loss 0.0364 Acc 0.7141\n",
            "Epoch 11 Batch 600 Loss 0.0370 Acc 0.7146\n",
            "Epoch 11 Batch 700 Loss 0.0365 Acc 0.7149\n",
            "Epoch 11 Batch 800 Loss 0.0362 Acc 0.7150\n",
            "Epoch 11 Batch 900 Loss 0.0359 Acc 0.7157\n",
            "Epoch 11 Batch 1000 Loss 0.0355 Acc 0.7159\n",
            "Epoch 11 Batch 1100 Loss 0.0352 Acc 0.7159\n",
            "Epoch 11 Batch 1200 Loss 0.0352 Acc 0.7162\n",
            "Epoch 11 Batch 1300 Loss 0.0349 Acc 0.7165\n",
            "Epoch 11 Batch 1400 Loss 0.0345 Acc 0.7165\n",
            "Epoch 11 Batch 1500 Loss 0.0343 Acc 0.7166\n",
            "Epoch 11 Batch 1600 Loss 0.0342 Acc 0.7166\n",
            "Epoch 11 Batch 1700 Loss 0.0341 Acc 0.7165\n",
            "Epoch 11 Batch 1800 Loss 0.0340 Acc 0.7165\n",
            "Epoch 11 Loss 0.0338 Acc 0.7166\n",
            "Time taken for 1 epoch: 139.66822981834412 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0277 Acc 0.7436\n",
            "Epoch 12 Batch 100 Loss 0.0284 Acc 0.7195\n",
            "Epoch 12 Batch 200 Loss 0.0283 Acc 0.7200\n",
            "Epoch 12 Batch 300 Loss 0.0281 Acc 0.7199\n",
            "Epoch 12 Batch 400 Loss 0.0287 Acc 0.7177\n",
            "Epoch 12 Batch 500 Loss 0.0286 Acc 0.7181\n",
            "Epoch 12 Batch 600 Loss 0.0291 Acc 0.7177\n",
            "Epoch 12 Batch 700 Loss 0.0290 Acc 0.7178\n",
            "Epoch 12 Batch 800 Loss 0.0289 Acc 0.7176\n",
            "Epoch 12 Batch 900 Loss 0.0292 Acc 0.7174\n",
            "Epoch 12 Batch 1000 Loss 0.0291 Acc 0.7172\n",
            "Epoch 12 Batch 1100 Loss 0.0291 Acc 0.7176\n",
            "Epoch 12 Batch 1200 Loss 0.0294 Acc 0.7179\n",
            "Epoch 12 Batch 1300 Loss 0.0294 Acc 0.7176\n",
            "Epoch 12 Batch 1400 Loss 0.0292 Acc 0.7176\n",
            "Epoch 12 Batch 1500 Loss 0.0291 Acc 0.7174\n",
            "Epoch 12 Batch 1600 Loss 0.0290 Acc 0.7174\n",
            "Epoch 12 Batch 1700 Loss 0.0295 Acc 0.7176\n",
            "Epoch 12 Batch 1800 Loss 0.0294 Acc 0.7177\n",
            "Epoch 12 Loss 0.0293 Acc 0.7179\n",
            "Time taken for 1 epoch: 139.60520958900452 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0363 Acc 0.6250\n",
            "Epoch 13 Batch 100 Loss 0.0252 Acc 0.7159\n",
            "Epoch 13 Batch 200 Loss 0.0260 Acc 0.7184\n",
            "Epoch 13 Batch 300 Loss 0.0266 Acc 0.7207\n",
            "Epoch 13 Batch 400 Loss 0.0270 Acc 0.7190\n",
            "Epoch 13 Batch 500 Loss 0.0274 Acc 0.7183\n",
            "Epoch 13 Batch 600 Loss 0.0275 Acc 0.7182\n",
            "Epoch 13 Batch 700 Loss 0.0272 Acc 0.7188\n",
            "Epoch 13 Batch 800 Loss 0.0270 Acc 0.7185\n",
            "Epoch 13 Batch 900 Loss 0.0270 Acc 0.7186\n",
            "Epoch 13 Batch 1000 Loss 0.0272 Acc 0.7188\n",
            "Epoch 13 Batch 1100 Loss 0.0267 Acc 0.7185\n",
            "Epoch 13 Batch 1200 Loss 0.0267 Acc 0.7184\n",
            "Epoch 13 Batch 1300 Loss 0.0265 Acc 0.7184\n",
            "Epoch 13 Batch 1400 Loss 0.0265 Acc 0.7187\n",
            "Epoch 13 Batch 1500 Loss 0.0264 Acc 0.7191\n",
            "Epoch 13 Batch 1600 Loss 0.0263 Acc 0.7189\n",
            "Epoch 13 Batch 1700 Loss 0.0262 Acc 0.7187\n",
            "Epoch 13 Batch 1800 Loss 0.0263 Acc 0.7185\n",
            "Epoch 13 Loss 0.0264 Acc 0.7185\n",
            "Time taken for 1 epoch: 138.9527199268341 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0244 Acc 0.7223\n",
            "Epoch 14 Batch 100 Loss 0.0235 Acc 0.7246\n",
            "Epoch 14 Batch 200 Loss 0.0249 Acc 0.7172\n",
            "Epoch 14 Batch 300 Loss 0.0263 Acc 0.7158\n",
            "Epoch 14 Batch 400 Loss 0.0264 Acc 0.7165\n",
            "Epoch 14 Batch 500 Loss 0.0261 Acc 0.7166\n",
            "Epoch 14 Batch 600 Loss 0.0267 Acc 0.7168\n",
            "Epoch 14 Batch 700 Loss 0.0270 Acc 0.7166\n",
            "Epoch 14 Batch 800 Loss 0.0267 Acc 0.7169\n",
            "Epoch 14 Batch 900 Loss 0.0263 Acc 0.7175\n",
            "Epoch 14 Batch 1000 Loss 0.0261 Acc 0.7172\n",
            "Epoch 14 Batch 1100 Loss 0.0260 Acc 0.7173\n",
            "Epoch 14 Batch 1200 Loss 0.0258 Acc 0.7176\n",
            "Epoch 14 Batch 1300 Loss 0.0257 Acc 0.7173\n",
            "Epoch 14 Batch 1400 Loss 0.0256 Acc 0.7179\n",
            "Epoch 14 Batch 1500 Loss 0.0254 Acc 0.7180\n",
            "Epoch 14 Batch 1600 Loss 0.0253 Acc 0.7179\n",
            "Epoch 14 Batch 1700 Loss 0.0252 Acc 0.7181\n",
            "Epoch 14 Batch 1800 Loss 0.0251 Acc 0.7184\n",
            "Epoch 14 Loss 0.0248 Acc 0.7184\n",
            "Time taken for 1 epoch: 140.7077944278717 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0165 Acc 0.6582\n",
            "Epoch 15 Batch 100 Loss 0.0196 Acc 0.7168\n",
            "Epoch 15 Batch 200 Loss 0.0207 Acc 0.7178\n",
            "Epoch 15 Batch 300 Loss 0.0214 Acc 0.7171\n",
            "Epoch 15 Batch 400 Loss 0.0225 Acc 0.7171\n",
            "Epoch 15 Batch 500 Loss 0.0228 Acc 0.7178\n",
            "Epoch 15 Batch 600 Loss 0.0229 Acc 0.7181\n",
            "Epoch 15 Batch 700 Loss 0.0229 Acc 0.7179\n",
            "Epoch 15 Batch 800 Loss 0.0230 Acc 0.7187\n",
            "Epoch 15 Batch 900 Loss 0.0231 Acc 0.7186\n",
            "Epoch 15 Batch 1000 Loss 0.0230 Acc 0.7185\n",
            "Epoch 15 Batch 1100 Loss 0.0228 Acc 0.7189\n",
            "Epoch 15 Batch 1200 Loss 0.0228 Acc 0.7192\n",
            "Epoch 15 Batch 1300 Loss 0.0229 Acc 0.7188\n",
            "Epoch 15 Batch 1400 Loss 0.0229 Acc 0.7188\n",
            "Epoch 15 Batch 1500 Loss 0.0228 Acc 0.7191\n",
            "Epoch 15 Batch 1600 Loss 0.0227 Acc 0.7190\n",
            "Epoch 15 Batch 1700 Loss 0.0227 Acc 0.7192\n",
            "Epoch 15 Batch 1800 Loss 0.0235 Acc 0.7192\n",
            "Epoch 15 Loss 0.0239 Acc 0.7192\n",
            "Time taken for 1 epoch: 139.9894585609436 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0444 Acc 0.6615\n",
            "Epoch 16 Batch 100 Loss 0.0232 Acc 0.7193\n",
            "Epoch 16 Batch 200 Loss 0.0219 Acc 0.7169\n",
            "Epoch 16 Batch 300 Loss 0.0222 Acc 0.7196\n",
            "Epoch 16 Batch 400 Loss 0.0219 Acc 0.7219\n",
            "Epoch 16 Batch 500 Loss 0.0220 Acc 0.7212\n",
            "Epoch 16 Batch 600 Loss 0.0218 Acc 0.7202\n",
            "Epoch 16 Batch 700 Loss 0.0221 Acc 0.7202\n",
            "Epoch 16 Batch 800 Loss 0.0221 Acc 0.7198\n",
            "Epoch 16 Batch 900 Loss 0.0220 Acc 0.7201\n",
            "Epoch 16 Batch 1000 Loss 0.0219 Acc 0.7197\n",
            "Epoch 16 Batch 1100 Loss 0.0217 Acc 0.7202\n",
            "Epoch 16 Batch 1200 Loss 0.0217 Acc 0.7206\n",
            "Epoch 16 Batch 1300 Loss 0.0217 Acc 0.7200\n",
            "Epoch 16 Batch 1400 Loss 0.0216 Acc 0.7201\n",
            "Epoch 16 Batch 1500 Loss 0.0216 Acc 0.7201\n",
            "Epoch 16 Batch 1600 Loss 0.0215 Acc 0.7201\n",
            "Epoch 16 Batch 1700 Loss 0.0218 Acc 0.7201\n",
            "Epoch 16 Batch 1800 Loss 0.0217 Acc 0.7202\n",
            "Epoch 16 Loss 0.0216 Acc 0.7201\n",
            "Time taken for 1 epoch: 140.3438220024109 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0161 Acc 0.6484\n",
            "Epoch 17 Batch 100 Loss 0.0207 Acc 0.7190\n",
            "Epoch 17 Batch 200 Loss 0.0209 Acc 0.7167\n",
            "Epoch 17 Batch 300 Loss 0.0210 Acc 0.7181\n",
            "Epoch 17 Batch 400 Loss 0.0214 Acc 0.7196\n",
            "Epoch 17 Batch 500 Loss 0.0213 Acc 0.7196\n",
            "Epoch 17 Batch 600 Loss 0.0213 Acc 0.7199\n",
            "Epoch 17 Batch 700 Loss 0.0211 Acc 0.7197\n",
            "Epoch 17 Batch 800 Loss 0.0208 Acc 0.7202\n",
            "Epoch 17 Batch 900 Loss 0.0211 Acc 0.7195\n",
            "Epoch 17 Batch 1000 Loss 0.0213 Acc 0.7192\n",
            "Epoch 17 Batch 1100 Loss 0.0212 Acc 0.7194\n",
            "Epoch 17 Batch 1200 Loss 0.0210 Acc 0.7201\n",
            "Epoch 17 Batch 1300 Loss 0.0211 Acc 0.7202\n",
            "Epoch 17 Batch 1400 Loss 0.0209 Acc 0.7204\n",
            "Epoch 17 Batch 1500 Loss 0.0207 Acc 0.7205\n",
            "Epoch 17 Batch 1600 Loss 0.0207 Acc 0.7201\n",
            "Epoch 17 Batch 1700 Loss 0.0210 Acc 0.7203\n",
            "Epoch 17 Batch 1800 Loss 0.0208 Acc 0.7205\n",
            "Epoch 17 Loss 0.0206 Acc 0.7204\n",
            "Time taken for 1 epoch: 140.79517126083374 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0161 Acc 0.7060\n",
            "Epoch 18 Batch 100 Loss 0.0197 Acc 0.7129\n",
            "Epoch 18 Batch 200 Loss 0.0191 Acc 0.7170\n",
            "Epoch 18 Batch 300 Loss 0.0190 Acc 0.7188\n",
            "Epoch 18 Batch 400 Loss 0.0187 Acc 0.7193\n",
            "Epoch 18 Batch 500 Loss 0.0189 Acc 0.7191\n",
            "Epoch 18 Batch 600 Loss 0.0193 Acc 0.7196\n",
            "Epoch 18 Batch 700 Loss 0.0193 Acc 0.7193\n",
            "Epoch 18 Batch 800 Loss 0.0192 Acc 0.7198\n",
            "Epoch 18 Batch 900 Loss 0.0190 Acc 0.7203\n",
            "Epoch 18 Batch 1000 Loss 0.0191 Acc 0.7201\n",
            "Epoch 18 Batch 1100 Loss 0.0191 Acc 0.7198\n",
            "Epoch 18 Batch 1200 Loss 0.0189 Acc 0.7198\n",
            "Epoch 18 Batch 1300 Loss 0.0189 Acc 0.7195\n",
            "Epoch 18 Batch 1400 Loss 0.0190 Acc 0.7195\n",
            "Epoch 18 Batch 1500 Loss 0.0189 Acc 0.7196\n",
            "Epoch 18 Batch 1600 Loss 0.0188 Acc 0.7196\n",
            "Epoch 18 Batch 1700 Loss 0.0188 Acc 0.7197\n",
            "Epoch 18 Batch 1800 Loss 0.0188 Acc 0.7199\n",
            "Epoch 18 Loss 0.0188 Acc 0.7199\n",
            "Time taken for 1 epoch: 139.45077395439148 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0285 Acc 0.6608\n",
            "Epoch 19 Batch 100 Loss 0.0181 Acc 0.7189\n",
            "Epoch 19 Batch 200 Loss 0.0177 Acc 0.7197\n",
            "Epoch 19 Batch 300 Loss 0.0176 Acc 0.7211\n",
            "Epoch 19 Batch 400 Loss 0.0175 Acc 0.7219\n",
            "Epoch 19 Batch 500 Loss 0.0177 Acc 0.7210\n",
            "Epoch 19 Batch 600 Loss 0.0184 Acc 0.7197\n",
            "Epoch 19 Batch 700 Loss 0.0183 Acc 0.7197\n",
            "Epoch 19 Batch 800 Loss 0.0179 Acc 0.7198\n",
            "Epoch 19 Batch 900 Loss 0.0178 Acc 0.7200\n",
            "Epoch 19 Batch 1000 Loss 0.0178 Acc 0.7202\n",
            "Epoch 19 Batch 1100 Loss 0.0179 Acc 0.7202\n",
            "Epoch 19 Batch 1200 Loss 0.0182 Acc 0.7203\n",
            "Epoch 19 Batch 1300 Loss 0.0180 Acc 0.7202\n",
            "Epoch 19 Batch 1400 Loss 0.0180 Acc 0.7203\n",
            "Epoch 19 Batch 1500 Loss 0.0179 Acc 0.7202\n",
            "Epoch 19 Batch 1600 Loss 0.0177 Acc 0.7204\n",
            "Epoch 19 Batch 1700 Loss 0.0175 Acc 0.7206\n",
            "Epoch 19 Batch 1800 Loss 0.0176 Acc 0.7205\n",
            "Epoch 19 Loss 0.0176 Acc 0.7206\n",
            "Time taken for 1 epoch: 139.43912649154663 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0199 Acc 0.7411\n",
            "Epoch 20 Batch 100 Loss 0.0174 Acc 0.7242\n",
            "Epoch 20 Batch 200 Loss 0.0178 Acc 0.7233\n",
            "Epoch 20 Batch 300 Loss 0.0174 Acc 0.7235\n",
            "Epoch 20 Batch 400 Loss 0.0166 Acc 0.7224\n",
            "Epoch 20 Batch 500 Loss 0.0165 Acc 0.7224\n",
            "Epoch 20 Batch 600 Loss 0.0167 Acc 0.7217\n",
            "Epoch 20 Batch 700 Loss 0.0169 Acc 0.7212\n",
            "Epoch 20 Batch 800 Loss 0.0170 Acc 0.7204\n",
            "Epoch 20 Batch 900 Loss 0.0171 Acc 0.7204\n",
            "Epoch 20 Batch 1000 Loss 0.0173 Acc 0.7202\n",
            "Epoch 20 Batch 1100 Loss 0.0172 Acc 0.7205\n",
            "Epoch 20 Batch 1200 Loss 0.0171 Acc 0.7207\n",
            "Epoch 20 Batch 1300 Loss 0.0171 Acc 0.7206\n",
            "Epoch 20 Batch 1400 Loss 0.0175 Acc 0.7203\n",
            "Epoch 20 Batch 1500 Loss 0.0175 Acc 0.7203\n",
            "Epoch 20 Batch 1600 Loss 0.0174 Acc 0.7204\n",
            "Epoch 20 Batch 1700 Loss 0.0173 Acc 0.7207\n",
            "Epoch 20 Batch 1800 Loss 0.0173 Acc 0.7207\n",
            "Epoch 20 Loss 0.0173 Acc 0.7207\n",
            "Time taken for 1 epoch: 138.2177095413208 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ROSNAfLnEXX"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTT7M9UnsyM"
      },
      "source": [
        "def evaluate(eng_sentence):\n",
        "\n",
        "    # tokenize and add SOS & EOS\n",
        "    input = [english_tokenizer.vocab_size] + english_tokenizer.encode(eng_sentence) + [english_tokenizer.vocab_size+1]\n",
        "    input = np.asarray(input)\n",
        "    input = input[np.newaxis, :]\n",
        "\n",
        "    # target French sentence\n",
        "    target_input = [french_tokenizer.vocab_size] # SOS of French\n",
        "    target_input = np.asarray(target_input)\n",
        "    target_input = target_input[np.newaxis, :]\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        encoder_padding_mask, combined_mask, decoder_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "        prediction, _ = transformer(x = input,\n",
        "                                    y = target_input,\n",
        "                                    training = True,\n",
        "                                    encoder_padding_mask = encoder_padding_mask,\n",
        "                                    look_ahead_mask = combined_mask,\n",
        "                                    decoder_padding_mask = decoder_padding_mask)\n",
        "\n",
        "        prediction = prediction[:, -1:, :]\n",
        "\n",
        "        prediction_index = tf.cast(tf.argmax(prediction, axis = -1), tf.int32)\n",
        "\n",
        "        # stop if EOS is predicted\n",
        "        if prediction_index == french_tokenizer.vocab_size + 1:\n",
        "            return tf.squeeze(target_input, axis = 0)\n",
        "\n",
        "        target_input = tf.concat([target_input, prediction_index], axis = -1)\n",
        "\n",
        "    return tf.squeeze(target_input, axis = 0)\n",
        "\n",
        "\n",
        "def translate(eng_sentence, fr_sentence):\n",
        "\n",
        "    translation = french_tokenizer.decode([w for w in evaluate(eng_sentence) if w < french_tokenizer.vocab_size])\n",
        "\n",
        "    print(\"[eng]\\n{}\".format(eng_sentence))\n",
        "    \n",
        "    print(\"[fr]\\n{}\".format(translation))\n",
        "\n",
        "    if fr_sentence:\n",
        "        print(\"[ans]\\n{}\".format(fr_sentence))"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEA0QLqH7zdr"
      },
      "source": [
        "# Translation by Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lQpI270uZJ_",
        "outputId": "823195e4-7d06-4d49-f16b-3f593aa0d080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "idx = np.random.randint(low = 0, high = len(X_test))\n",
        "\n",
        "translate(X_test[idx], Y_test[idx])"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[eng]\n",
            "new jersey is sometimes wet during october , and it is usually rainy in spring .\n",
            "[fr]\n",
            "new jersey est parfois humide en octobre , et il est généralement pluvieux au printemps .\n",
            "[ans]\n",
            "new jersey est parfois humide en octobre , et il est généralement pluvieux au printemps .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-noyF_K_XR5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}